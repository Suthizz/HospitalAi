# -*- coding: utf-8 -*-
import os
import json
import joblib
import numpy as np
import pandas as pd
import streamlit as st
from catboost import CatBoostClassifier # Needed even when loading model
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder # Needed for preprocessing

# ----------------------------------------------------------
# ‚öôÔ∏è Page Setup
# ----------------------------------------------------------
st.set_page_config(page_title="Road Accident AI Decision Support", page_icon="üè•", layout="wide")
st.title("üè• Road Accident AI for Clinical Decision Support")
st.caption("‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•")

# --- Define File Paths ---
MODEL_PATH = "predict_catboost_multi.pkl"
ENCODERS_PATH = "encoders_multi.pkl"
FEATURES_PATH = "features_multi.json"
KMEANS_PATH = "kmeans_cluster_model.pkl"
SCALER_PATH = "scaler_cluster.pkl"
RULES_MINOR_PATH = "apriori_rules_minor.pkl"
RULES_SEVERE_PATH = "apriori_rules_severe.pkl"
RULES_FATAL_PATH = "apriori_rules_fatal.pkl"
LOG_FILE = "prediction_log.csv"

# ----------------------------------------------------------
# üì¶ Load Models + Show in Expander (Improved Error Handling)
# ----------------------------------------------------------
@st.cache_resource
def load_all():
    """Loads all necessary model files and returns them."""
    loaded_items = {}
    msgs = []

    files_to_load = {
        "model": (MODEL_PATH, "Clinical Severity Model"),
        "encoders": (ENCODERS_PATH, "Encoders for Clinical Data"),
        "features": (FEATURES_PATH, "Model Features Configuration"),
        "kmeans": (KMEANS_PATH, "KMeans Clustering Model"),
        "scaler": (SCALER_PATH, "Scaler for Clustering"),
        "rules_minor": (RULES_MINOR_PATH, "Apriori Rules (Minor)"),
        "rules_severe": (RULES_SEVERE_PATH, "Apriori Rules (Severe)"),
        "rules_fatal": (RULES_FATAL_PATH, "Apriori Rules (Fatal)"),
    }

    for key, (path, description) in files_to_load.items():
        try:
            if path.endswith(".json"):
                with open(path, "r", encoding="utf-8") as f:
                    loaded_items[key] = json.load(f)
            else: # .pkl files
                loaded_items[key] = joblib.load(path)
            msgs.append(f"‚úÖ {os.path.basename(path)} ‚Äî {description}")
        except FileNotFoundError:
            loaded_items[key] = None # Or [] for features
            if key == 'features': loaded_items[key] = []
            if key == 'encoders': loaded_items[key] = {}
            msgs.append(f"‚ùå File not found: {os.path.basename(path)} ‚Äî {description}")
        except Exception as e:
            loaded_items[key] = None # Or [] for features
            if key == 'features': loaded_items[key] = []
            if key == 'encoders': loaded_items[key] = {}
            msgs.append(f"‚ö†Ô∏è Error loading {os.path.basename(path)}: {e}")

    # Display loading status
    with st.expander("üìÇ File Loading Status", expanded=False):
        all_loaded = all(item is not None and item != [] and item != {} for key, item in loaded_items.items() if key != 'encoders') # Encoders can be {} initially
        if all_loaded:
            st.success("All required files loaded successfully.")
        else:
            st.warning("Some files could not be loaded. Please check file paths and availability.")

        for m in msgs:
            if "‚úÖ" in m:
                st.caption(m)
            else:
                st.caption(f":warning: {m}") # Highlight errors/warnings

    return (
        loaded_items.get("model"),
        loaded_items.get("encoders"),
        loaded_items.get("features"),
        loaded_items.get("kmeans"),
        loaded_items.get("scaler"),
        loaded_items.get("rules_minor"),
        loaded_items.get("rules_severe"),
        loaded_items.get("rules_fatal"),
    )

# ----------------------------------------------------------
# ‚úÖ Load resources using the function
# ----------------------------------------------------------
model, encoders, features, kmeans, scaler, rules_minor, rules_severe, rules_fatal = load_all()

# --- Check if essential components loaded ---
essentials_loaded = model and features and encoders is not None # Check essential components

# ----------------------------------------------------------
# üß© Manual Mappings & Helper Functions
# ----------------------------------------------------------
activity_mapping = {
    "0": "‡πÄ‡∏î‡∏¥‡∏ô‡πÄ‡∏ó‡πâ‡∏≤", "1": "‡πÇ‡∏î‡∏¢‡∏™‡∏≤‡∏£‡∏û‡∏≤‡∏´‡∏ô‡∏∞‡∏™‡∏≤‡∏ò‡∏≤‡∏£‡∏ì‡∏∞", "2": "‡πÇ‡∏î‡∏¢‡∏™‡∏≤‡∏£‡∏û‡∏≤‡∏´‡∏ô‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•",
    "3": "‡∏Ç‡∏±‡∏ö‡∏Ç‡∏µ‡πà‡∏û‡∏≤‡∏´‡∏ô‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•", "4": "‡∏ó‡∏≥‡∏á‡∏≤‡∏ô", "5": "‡πÄ‡∏•‡πà‡∏ô‡∏Å‡∏µ‡∏¨‡∏≤", "6": "‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏≠‡∏∑‡πà‡∏ô ‡πÜ"
}
aplace_mapping = {
    "10": "‡∏ö‡πâ‡∏≤‡∏ô‡∏û‡∏±‡∏Å‡∏≠‡∏≤‡∏®‡∏±‡∏¢", "11": "‡∏ñ‡∏ô‡∏ô/‡∏ó‡∏≤‡∏á‡∏´‡∏•‡∏ß‡∏á", "12": "‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô",
    "13": "‡πÇ‡∏£‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô/‡∏™‡∏ñ‡∏≤‡∏ö‡∏±‡∏ô‡∏®‡∏∂‡∏Å‡∏©‡∏≤", "14": "‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏ò‡∏≤‡∏£‡∏ì‡∏∞", "15": "‡∏≠‡∏∑‡πà‡∏ô ‡πÜ"
}
prov_mapping = {
    "10": "‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£", "20": "‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà", "30": "‡∏Ç‡∏≠‡∏ô‡πÅ‡∏Å‡πà‡∏ô", "40": "‡∏†‡∏π‡πÄ‡∏Å‡πá‡∏ï",
    "50": "‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤", "60": "‡∏™‡∏á‡∏Ç‡∏•‡∏≤", "99": "‡∏≠‡∏∑‡πà‡∏ô ‡πÜ"
}
severity_map = {0: "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ô‡πâ‡∏≠‡∏¢", 1: "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á", 2: "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å"}
advice_map = {
    "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ô‡πâ‡∏≠‡∏¢": "‡∏î‡∏π‡πÅ‡∏•‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡πÄ‡∏ù‡πâ‡∏≤‡∏£‡∏∞‡∏ß‡∏±‡∏á‡∏ã‡πâ‡∏≥‡∏ó‡∏∏‡∏Å 15‚Äì30 ‡∏ô‡∏≤‡∏ó‡∏µ",
    "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á": "‡∏™‡πà‡∏á‡∏ï‡∏£‡∏ß‡∏à‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏£‡∏ô‡πâ‡∏≥ / ‡∏¢‡∏≤‡πÅ‡∏Å‡πâ‡∏õ‡∏ß‡∏î / ‡πÄ‡∏ù‡πâ‡∏≤‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏ä‡∏µ‡∏û‡πÉ‡∏Å‡∏•‡πâ‡∏ä‡∏¥‡∏î",
    "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å": "‡πÅ‡∏à‡πâ‡∏á‡∏ó‡∏µ‡∏°‡∏™‡∏´‡∏™‡∏≤‡∏Ç‡∏≤ ‡πÄ‡∏õ‡∏¥‡∏î‡∏ó‡∏≤‡∏á‡πÄ‡∏î‡∏¥‡∏ô‡∏´‡∏≤‡∏¢‡πÉ‡∏à ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏´‡πâ‡∏≠‡∏á‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏™‡πà‡∏á‡∏ï‡πà‡∏≠‡∏î‡πà‡∏ß‡∏ô"
}
triage_color = {"‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ô‡πâ‡∏≠‡∏¢": "#4CAF50", "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á": "#FFC107", "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å": "#F44336"}

# --- Preprocessing Function (Modified to use loaded features/encoders) ---
def preprocess_input(data_dict, loaded_encoders, expected_features):
    """Preprocesses user input dictionary based on loaded encoders and features."""
    if not expected_features:
        st.error("Feature list is empty. Cannot preprocess.")
        return None

    df = pd.DataFrame([data_dict])

    # Map display values back to codes before encoding
    reverse_activity = {v: k for k, v in activity_mapping.items()}
    reverse_aplace = {v: k for k, v in aplace_mapping.items()}
    reverse_prov = {v: k for k, v in prov_mapping.items()}

    df['activity'] = df['activity'].map(reverse_activity).fillna("Unknown") # Map or default
    df['aplace'] = df['aplace'].map(reverse_aplace).fillna("Unknown")
    df['prov'] = df['prov'].map(reverse_prov).fillna("Unknown")

    # Reindex first to ensure all expected columns are present
    df = df.reindex(columns=expected_features, fill_value=0)

    # Clean potential string issues and fill NaNs *after* reindexing
    clean_values = ["Unknown", "None", "N/A", "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏", "N", "nan", "NaN", "", " "]
    df = df.replace(clean_values, np.nan).fillna(0)

    # Encode categorical features using loaded encoders
    if loaded_encoders:
      for col, le in loaded_encoders.items():
          if col in df.columns:
              # Convert column to string before applying transform
              df[col] = df[col].astype(str)
              # Handle unseen labels by mapping them to a default index (e.g., 0)
              df[col] = df[col].apply(lambda x: le.transform([x])[0] if x in le.classes_ else 0)
    else:
        # If encoders didn't load, attempt basic numeric conversion for non-numeric looking columns
        for col in df.columns:
             if df[col].dtype == 'object':
                 df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)


    # --- Create Engineered Features (must match training - check feature list) ---
    # Ensure necessary base columns exist before creating engineered ones
    if 'age' in df.columns:
        df['age'] = pd.to_numeric(df['age'], errors='coerce').fillna(0)
        if "age_group_60plus" in expected_features:
             df["age_group_60plus"] = (df["age"] >= 60).astype(int)

    risk_cols_in_features = [f"risk{i}" for i in range(1, 6) if f"risk{i}" in expected_features]
    if "risk_count" in expected_features and risk_cols_in_features:
        df["risk_count"] = df[risk_cols_in_features].sum(axis=1)
    elif "risk_count" in expected_features: # If risk_count expected but base risks aren't
         df["risk_count"] = 0


    if 'is_night' in df.columns:
        df['is_night'] = pd.to_numeric(df['is_night'], errors='coerce').fillna(0)
        if "night_flag" in expected_features:
            df["night_flag"] = df["is_night"].astype(int)
    elif "night_flag" in expected_features: # If night_flag expected but is_night isn't
         df["night_flag"] = 0


    # Ensure all columns are numeric and fill any remaining NaNs
    for col in df.columns:
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)


    # Final check: Ensure column order matches exactly and return
    try:
        df = df[expected_features]
    except KeyError as e:
        st.error(f"Mismatch in expected features during preprocessing. Missing: {e}")
        return None

    return df


# --- Function to decode Apriori rules ---
def decode_set(item_set):
    """Converts a frozenset of coded items to readable strings."""
    if not isinstance(item_set, (frozenset, set)):
        return str(item_set)

    # Define mappings (expand as needed based on your Apriori basket items)
    replacements = {
        "Male": "‡πÄ‡∏û‡∏®‡∏ä‡∏≤‡∏¢", "Female": "‡πÄ‡∏û‡∏®‡∏´‡∏ç‡∏¥‡∏á", "Age_60+": "‡∏≠‡∏≤‡∏¢‡∏∏ 60+",
        "Nighttime": "‡∏Å‡∏•‡∏≤‡∏á‡∏Ñ‡∏∑‡∏ô", "Head_Injury": "‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡∏®‡∏µ‡∏£‡∏©‡∏∞",
        "Risk_Alcohol": "‡∏î‡∏∑‡πà‡∏°‡πÅ‡∏≠‡∏•‡∏Å‡∏≠‡∏Æ‡∏≠‡∏•‡πå", "Risk_Drugs_General": "‡πÉ‡∏ä‡πâ‡∏¢‡∏≤‡πÄ‡∏™‡∏û‡∏ï‡∏¥‡∏î(‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ)",
        "Risk_No_Belt": "‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡πÄ‡∏Ç‡πá‡∏°‡∏Ç‡∏±‡∏î", "Risk_No_Helmet": "‡πÑ‡∏°‡πà‡∏™‡∏ß‡∏°‡∏´‡∏°‡∏ß‡∏Å",
        "Risk_Phone_Use": "‡πÉ‡∏ä‡πâ‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå‡∏Ç‡∏ì‡∏∞‡∏Ç‡∏±‡∏ö",
        "Drug_Kratom": "‡∏Å‡∏£‡∏∞‡∏ó‡πà‡∏≠‡∏°", "Drug_Cannabis": "‡∏Å‡∏±‡∏ç‡∏ä‡∏≤", "Drug_Amphetamine": "‡∏¢‡∏≤‡∏ö‡πâ‡∏≤",
        "Severity_Minor": "‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢", "Severity_Severe": "‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á",
        "Severity_Fatal": "‡πÄ‡∏™‡∏µ‡∏¢‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï"
        # Add more mappings if needed
    }
    readable = [replacements.get(str(item), str(item)) for item in sorted(list(item_set))]
    return ", ".join(readable)


# ==========================================================
# ü©∫ TAB SYSTEM
# ==========================================================
tab1, tab2, tab3, tab4 = st.tabs([
    "üß† Clinical Risk Prediction",
    "üë• Cluster Insight",
    "üß© Risk Association",
    "üìä Clinical Summary Dashboard"
])

# Initialize session state for submit button if it doesn't exist
if 'submit_pressed' not in st.session_state:
    st.session_state.submit_pressed = False
if 'prediction_label' not in st.session_state:
    st.session_state.prediction_label = "‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô"
if 'processed_input_for_tabs' not in st.session_state:
    st.session_state.processed_input_for_tabs = None
if 'raw_input_for_tabs' not in st.session_state:
    st.session_state.raw_input_for_tabs = {}


# ----------------------------------------------------------
# üß† TAB 1 ‚Äî CatBoost Prediction
# ----------------------------------------------------------
with tab1:
    st.subheader("üß† Clinical Severity Prediction")
    st.caption("‡∏£‡∏∞‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå")

    if not essentials_loaded:
        st.error("Cannot proceed with prediction. Essential model files (model, features, encoders) are missing.")
    else:
        st.subheader("üìã ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö")
        with st.form("input_form"):
            # --- Input fields ---
            age = st.number_input("‡∏≠‡∏≤‡∏¢‡∏∏ (‡∏õ‡∏µ)", min_value=0, max_value=120, value=35, key="tab1_age")
            sex = st.radio("‡πÄ‡∏û‡∏®", ["‡∏´‡∏ç‡∏¥‡∏á", "‡∏ä‡∏≤‡∏¢"], horizontal=True, key="tab1_sex") # Display text
            is_night = st.checkbox("‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏•‡∏≤‡∏á‡∏Ñ‡∏∑‡∏ô (18:00-06:00)", value=False, key="tab1_is_night")
            head_injury = st.checkbox("‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡∏ó‡∏µ‡πà‡∏®‡∏µ‡∏£‡∏©‡∏∞", value=False, key="tab1_head_injury")
            mass_casualty = st.checkbox("‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ú‡∏π‡πâ‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å", value=False, key="tab1_mass_casualty")

            st.markdown("**‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á (Risk Factors - ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏≤‡∏Å‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á)**")
            c1, c2, c3, c4, c5 = st.columns(5)
            # Use keys consistent with training data if possible, map later if needed
            with c1: risk1 = st.checkbox("‡∏î‡∏∑‡πà‡∏°‡πÅ‡∏≠‡∏•‡∏Å‡∏≠‡∏Æ‡∏≠‡∏•‡πå (risk1)", key="tab1_risk1")
            with c2: risk2 = st.checkbox("‡πÉ‡∏ä‡πâ‡∏¢‡∏≤‡πÄ‡∏™‡∏û‡∏ï‡∏¥‡∏î(‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ) (risk2)", key="tab1_risk2")
            with c3: risk3 = st.checkbox("‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡πÄ‡∏Ç‡πá‡∏°‡∏Ç‡∏±‡∏î (risk3)", key="tab1_risk3")
            with c4: risk4 = st.checkbox("‡πÑ‡∏°‡πà‡∏™‡∏ß‡∏°‡∏´‡∏°‡∏ß‡∏Å‡∏ô‡∏¥‡∏£‡∏†‡∏±‡∏¢ (risk4)", key="tab1_risk4")
            with c5: risk5 = st.checkbox("‡πÉ‡∏ä‡πâ‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå‡∏Ç‡∏ì‡∏∞‡∏Ç‡∏±‡∏ö (risk5)", key="tab1_risk5")

            st.markdown("**‡∏™‡∏≤‡∏£‡πÄ‡∏™‡∏û‡∏ï‡∏¥‡∏î/‡∏¢‡∏≤‡πÉ‡∏ô‡∏£‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏¢ (‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏≤‡∏Å‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á)**")
            d1, d2, d3 = st.columns(3)
            with d1: cannabis = st.checkbox("‡∏Å‡∏±‡∏ç‡∏ä‡∏≤", key="tab1_cannabis")
            with d2: amphetamine = st.checkbox("‡∏¢‡∏≤‡∏ö‡πâ‡∏≤ / ‡πÅ‡∏≠‡∏°‡πÄ‡∏ü‡∏ï‡∏≤‡∏°‡∏µ‡∏ô", key="tab1_amphetamine")
            with d3: drugs = st.checkbox("‡∏¢‡∏≤‡∏≠‡∏∑‡πà‡∏ô ‡πÜ (drugs)", key="tab1_drugs") # 'drugs' from notebook

            st.markdown("**‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Ç‡∏≠‡∏á‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå**")
            # Using text input for flexibility, assuming encoding handles variations/unknowns
            activity_display = st.selectbox("‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏Ç‡∏ì‡∏∞‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏", list(activity_mapping.values()), key="tab1_activity")
            aplace_display = st.selectbox("‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏", list(aplace_mapping.values()), key="tab1_aplace")
            prov_display = st.selectbox("‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏", list(prov_mapping.values()), key="tab1_prov")

            submit_button_tab1 = st.form_submit_button("üîé ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á")

        if submit_button_tab1:
            st.session_state.submit_pressed = True # Mark that form was submitted

            # --- Prepare input dictionary ---
            input_data = {
                "age": age,
                "sex": '1' if sex == "‡∏ä‡∏≤‡∏¢" else '2', # Map back to '1'/'2' code used in notebook
                "is_night": int(is_night),
                "head_injury": int(head_injury),
                "mass_casualty": int(mass_casualty),
                "risk1": int(risk1),
                "risk2": int(risk2),
                "risk3": int(risk3),
                "risk4": int(risk4),
                "risk5": int(risk5),
                "cannabis": int(cannabis),
                "amphetamine": int(amphetamine),
                "drugs": int(drugs),
                "activity": activity_display, # Keep display value for now, map in preprocess
                "aplace": aplace_display,
                "prov": prov_display
            }
             # Store raw input for other tabs
            st.session_state.raw_input_for_tabs = input_data.copy()


            # --- Preprocess and Predict ---
            X_input = preprocess_input(input_data, encoders, features)
            st.session_state.processed_input_for_tabs = X_input # Store processed input


            if X_input is not None:
                try:
                    probs = model.predict_proba(X_input)[0]
                    pred_class = int(np.argmax(probs))
                    st.session_state.prediction_label = severity_map.get(pred_class, "‡πÑ‡∏°‡πà‡∏ó‡∏£‡∏≤‡∏ö") # Store label
                    color = triage_color.get(st.session_state.prediction_label, "#2196F3") # Default blue

                    # Display Triage Color Box
                    st.markdown(
                        f"<div style='background-color:{color};padding:12px;border-radius:10px;margin-top: 15px;'>"
                        f"<h3 style='color:white;text-align:center;'>‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ì‡πå: {st.session_state.prediction_label}</h3></div>",
                        unsafe_allow_html=True
                    )
                    # Display Advice and Confidence
                    st.info(f"üí° ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô: {advice_map.get(st.session_state.prediction_label, 'N/A')}")
                    st.caption(f"üß† ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö: {probs[pred_class]*100:.1f}%")


                    # --- Save prediction log ---
                    try:
                        log_entry = {
                            "timestamp": pd.Timestamp.now(tz='Asia/Bangkok'), # Add timezone
                            "age": age,
                            "sex": sex,
                            "predicted_severity": st.session_state.prediction_label,
                            "prov": prov_display,
                             "is_night": int(is_night),
                             "risk1": int(risk1),
                             "risk2": int(risk2),
                             "risk3": int(risk3),
                             "risk4": int(risk4),
                             "risk5": int(risk5),
                             "head_injury": int(head_injury) # Add head injury to log
                        }
                        new_row = pd.DataFrame([log_entry])

                        if os.path.exists(LOG_FILE):
                            new_row.to_csv(LOG_FILE, mode="a", index=False, header=False, encoding='utf-8-sig')
                        else:
                            new_row.to_csv(LOG_FILE, index=False, encoding='utf-8-sig')
                        st.success("üìÅ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö Dashboard ‡πÅ‡∏•‡πâ‡∏ß")
                    except Exception as log_e:
                        st.warning(f"Could not save prediction log: {log_e}")

                except Exception as pred_e:
                    st.error(f"An error occurred during prediction: {pred_e}")
                    st.error("Please check the input data and model files.")
                    # st.dataframe(X_input) # Optional: show processed data for debugging
            else:
                 st.error("Input preprocessing failed. Cannot make prediction.")


# ----------------------------------------------------------
# üë• TAB 2 ‚Äî K-Means Cluster Analysis
# ----------------------------------------------------------
with tab2:
    st.subheader("üë• Patient Segmentation (K-Means)")
    st.caption("‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ú‡∏π‡πâ‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏™‡∏£‡∏£‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÄ‡∏ä‡∏¥‡∏á‡∏£‡∏∏‡∏Å")

    if not st.session_state.submit_pressed:
        st.info("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏Å‡∏î '‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á' ‡πÉ‡∏ô‡πÅ‡∏ó‡πá‡∏ö‡πÅ‡∏£‡∏Å‡∏Å‡πà‡∏≠‡∏ô")
    elif kmeans is None or scaler is None:
        st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏• K-Means ‡∏´‡∏£‡∏∑‡∏≠ Scaler ‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ß‡πâ")
    elif st.session_state.processed_input_for_tabs is None:
         st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Input ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Clustering ‡πÑ‡∏î‡πâ")
    else:
        # --- Display Patient Summary ---
        st.markdown("### üßæ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö")
        raw_input = st.session_state.raw_input_for_tabs
        summary_cols = st.columns(3)
        summary_cols[0].metric("‡∏≠‡∏≤‡∏¢‡∏∏", f"{raw_input.get('age', 'N/A')} ‡∏õ‡∏µ")
        summary_cols[1].metric("‡πÄ‡∏û‡∏®", '‡∏ä‡∏≤‡∏¢' if raw_input.get('sex') == '1' else '‡∏´‡∏ç‡∏¥‡∏á' if raw_input.get('sex') == '2' else 'N/A')
        summary_cols[2].metric("‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á", st.session_state.prediction_label)

        risk_summary = [
            "‡∏î‡∏∑‡πà‡∏°‡πÅ‡∏≠‡∏•‡∏Å‡∏≠‡∏Æ‡∏≠‡∏•‡πå" if raw_input.get('risk1') else None,
            "‡πÉ‡∏ä‡πâ‡∏¢‡∏≤‡πÄ‡∏™‡∏û‡∏ï‡∏¥‡∏î" if raw_input.get('risk2') else None,
            "‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡πÄ‡∏Ç‡πá‡∏°‡∏Ç‡∏±‡∏î" if raw_input.get('risk3') else None,
            "‡πÑ‡∏°‡πà‡∏™‡∏ß‡∏°‡∏´‡∏°‡∏ß‡∏Å" if raw_input.get('risk4') else None,
            "‡πÉ‡∏ä‡πâ‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå" if raw_input.get('risk5') else None,
            "‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡∏®‡∏µ‡∏£‡∏©‡∏∞" if raw_input.get('head_injury') else None,
        ]
        risk_summary = [r for r in risk_summary if r]
        st.markdown(f"**‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÄ‡∏î‡πà‡∏ô:** {', '.join(risk_summary) if risk_summary else '-'}")
        st.markdown("---")

        # --- Perform Clustering ---
        try:
            # Select columns used by the scaler during training
            if hasattr(scaler, "feature_names_in_"):
                cluster_features_used = scaler.feature_names_in_
                # Ensure the processed input has these columns
                X_input_cluster = st.session_state.processed_input_for_tabs.copy()
                # Add missing columns expected by scaler, fill with 0
                for col in cluster_features_used:
                    if col not in X_input_cluster.columns:
                        X_input_cluster[col] = 0
                X_input_cluster = X_input_cluster[cluster_features_used] # Select and order

            else:
                # Fallback if scaler doesn't have feature names (less reliable)
                st.warning("Scaler object does not contain feature names. Using numeric columns.")
                X_input_cluster = st.session_state.processed_input_for_tabs.select_dtypes(include=np.number)


            if not X_input_cluster.empty:
                X_scaled = scaler.transform(X_input_cluster)
                cluster_label = int(kmeans.predict(X_scaled)[0])

                # Example Cluster Descriptions (Adjust based on your actual cluster analysis)
                cluster_desc = {
                    0: "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ/‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ï‡πà‡∏≥: ‡∏°‡∏±‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏®‡∏ä‡∏≤‡∏¢ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡∏®‡∏µ‡∏£‡∏©‡∏∞‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏î‡πà‡∏ô‡∏ä‡∏±‡∏î",
                    1: "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á/‡∏´‡∏ç‡∏¥‡∏á: ‡∏°‡∏±‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏®‡∏´‡∏ç‡∏¥‡∏á ‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡∏®‡∏µ‡∏£‡∏©‡∏∞",
                    2: "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á/‡∏¢‡∏≤‡πÄ‡∏™‡∏û‡∏ï‡∏¥‡∏î: ‡∏û‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏¢‡∏≤‡πÄ‡∏™‡∏û‡∏ï‡∏¥‡∏î ‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡∏®‡∏µ‡∏£‡∏©‡∏∞‡∏£‡πà‡∏ß‡∏°"
                    # Add descriptions for all clusters found during analysis
                }

                st.markdown(f"### üìä ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°: **Cluster {cluster_label}**")
                st.info(f"**‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Å‡∏•‡∏∏‡πà‡∏°:** {cluster_desc.get(cluster_label, '‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ô‡∏µ‡πâ')}")
                st.caption("üí° ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô ‡πÅ‡∏•‡∏∞‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏Ñ‡∏°‡πÄ‡∏õ‡∏ç‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢")

            else:
                 st.error("Could not extract valid features for clustering from the input.")

        except Exception as e:
            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏° K-Means: {e}")
            # st.dataframe(X_input_cluster) # Optional debugging


# ----------------------------------------------------------
# üß© TAB 3 ‚Äî Apriori Risk Association
# ----------------------------------------------------------
with tab3:
    st.subheader("üß© Risk Association Analysis (Apriori)")
    st.caption("‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡πÄ‡∏ä‡∏¥‡∏á‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢")

    if not st.session_state.submit_pressed:
        st.info("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏Å‡∏î '‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á' ‡πÉ‡∏ô‡πÅ‡∏ó‡πá‡∏ö‡πÅ‡∏£‡∏Å‡∏Å‡πà‡∏≠‡∏ô")
    elif rules_minor is None and rules_severe is None and rules_fatal is None:
        st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Å‡∏é Apriori ‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ß‡πâ")
    else:
        # --- Display Patient Summary ---
        st.markdown("### üßæ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö")
        raw_input = st.session_state.raw_input_for_tabs
        summary_cols = st.columns(3)
        summary_cols[0].metric("‡∏≠‡∏≤‡∏¢‡∏∏", f"{raw_input.get('age', 'N/A')} ‡∏õ‡∏µ")
        summary_cols[1].metric("‡πÄ‡∏û‡∏®", '‡∏ä‡∏≤‡∏¢' if raw_input.get('sex') == '1' else '‡∏´‡∏ç‡∏¥‡∏á' if raw_input.get('sex') == '2' else 'N/A')
        summary_cols[2].metric("‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á", st.session_state.prediction_label)

        risk_tags = [
            "‡∏î‡∏∑‡πà‡∏°‡πÅ‡∏≠‡∏•‡∏Å‡∏≠‡∏Æ‡∏≠‡∏•‡πå" if raw_input.get('risk1') else None,
            "‡πÉ‡∏ä‡πâ‡∏¢‡∏≤‡πÄ‡∏™‡∏û‡∏ï‡∏¥‡∏î" if raw_input.get('risk2') else None,
            "‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡πÄ‡∏Ç‡πá‡∏°‡∏Ç‡∏±‡∏î" if raw_input.get('risk3') else None,
            "‡πÑ‡∏°‡πà‡∏™‡∏ß‡∏°‡∏´‡∏°‡∏ß‡∏Å" if raw_input.get('risk4') else None,
            "‡πÉ‡∏ä‡πâ‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå" if raw_input.get('risk5') else None,
            "‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡∏®‡∏µ‡∏£‡∏©‡∏∞" if raw_input.get('head_injury') else None,
        ]
        risk_tags = [r for r in risk_tags if r]
        st.markdown(f"**‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÄ‡∏î‡πà‡∏ô:** {', '.join(risk_tags) if risk_tags else '-'}")
        st.markdown("---")

        # --- Select and Display Relevant Rules ---
        st.markdown("### üîó ‡∏Å‡∏é‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á (Top 5 by Lift)")

        target_label = st.session_state.prediction_label
        rules_df_to_show = None
        rules_title = f"‡∏Å‡∏é‡∏ó‡∏µ‡πà‡∏ô‡∏≥‡πÑ‡∏õ‡∏™‡∏π‡πà: {target_label}"

        if target_label == "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ô‡πâ‡∏≠‡∏¢" and rules_minor is not None and not rules_minor.empty:
            rules_df_to_show = rules_minor
        elif target_label == "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á" and rules_severe is not None and not rules_severe.empty:
            rules_df_to_show = rules_severe
        elif target_label == "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å" and rules_fatal is not None and not rules_fatal.empty:
            rules_df_to_show = rules_fatal

        if rules_df_to_show is not None:
            st.markdown(f"**{rules_title}**")
            # Decode antecedents and consequents for display
            display_df = rules_df_to_show.head(5).copy()
            if 'antecedents' in display_df.columns:
                 display_df["‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ô‡∏≥ (Antecedents)"] = display_df["antecedents"].apply(decode_set)
            if 'consequents' in display_df.columns:
                 display_df["‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (Consequents)"] = display_df["consequents"].apply(decode_set)

            # Select and rename columns for clarity
            display_df = display_df.rename(columns={
                "support": "Support", "confidence": "Confidence", "lift": "Lift"
            })
            st.dataframe(
                display_df[["‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ô‡∏≥ (Antecedents)", "‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (Consequents)", "Support", "Confidence", "Lift"]],
                use_container_width=True,
                hide_index=True
            )

            # Display interpretation guide
            st.markdown("üìò **‡∏Å‡∏≤‡∏£‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°:**")
            st.markdown("- **Support:** ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ñ‡∏™‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ô‡∏≥‡πÅ‡∏•‡∏∞‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ô‡∏µ‡πâ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô")
            st.markdown("- **Confidence:** ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏Å‡∏¥‡∏î '‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå' ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏û‡∏ö '‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ô‡∏≥' ‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ")
            st.markdown("- **Lift > 1:** ‡∏ö‡πà‡∏á‡∏ä‡∏µ‡πâ‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏ô‡∏±‡∏¢‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ö‡∏±‡∏á‡πÄ‡∏≠‡∏¥‡∏ç) ‡∏¢‡∏¥‡πà‡∏á‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á‡∏¢‡∏¥‡πà‡∏á‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏Å‡∏±‡∏ô‡∏°‡∏≤‡∏Å")

        else:
            st.info(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Å‡∏é Apriori ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á '{target_label}' ‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ")


# ----------------------------------------------------------
# üìä TAB 4 ‚Äî Clinical Summary Dashboard
# ----------------------------------------------------------
with tab4:
    st.subheader("üìä Clinical Summary & Insights Dashboard")
    st.caption("‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏ú‡∏π‡πâ‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏ö AI ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡πÄ‡∏ä‡∏¥‡∏á‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå‡πÅ‡∏•‡∏∞‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•")

    # --- Load Log File ---
    df_log = None
    if os.path.exists(LOG_FILE):
        try:
            df_log = pd.read_csv(LOG_FILE, parse_dates=['timestamp'])
            df_log['timestamp'] = pd.to_datetime(df_log['timestamp']).dt.tz_localize(None) # Remove timezone for consistency if needed
            if not df_log.empty:
                 st.success(f"üìÅ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Log ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(df_log):,} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
            else:
                 st.info("‡πÑ‡∏ü‡∏•‡πå Log ‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤")
                 df_log = None # Treat empty log as if it doesn't exist for checks below
        except Exception as e:
            st.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Log ({LOG_FILE}): {e}")
            df_log = None
    else:
        st.info("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Log ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢")

    # --- Reset Button ---
    if st.button("üßπ ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Log ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"):
        if os.path.exists(LOG_FILE):
            try:
                os.remove(LOG_FILE)
                st.success("‚úÖ ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Log ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
                df_log = None # Update state after deletion
                st.rerun() # Rerun to reflect the change immediately
            except Exception as e:
                st.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå Log: {e}")
        else:
            st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå Log ‡πÉ‡∏´‡πâ‡∏•‡∏ö")

    st.markdown("---")

    # --- Dashboard Content (only if log exists and is not empty) ---
    if df_log is not None and not df_log.empty:
        total_cases = len(df_log)

        # --- KPI Overview ---
        st.markdown("### üí° ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå (KPI Overview)")
        col1_kpi, col2_kpi, col3_kpi = st.columns(3)

        fatal_ratio = df_log["predicted_severity"].eq("‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å").mean() * 100
        avg_age = df_log["age"].mean() if 'age' in df_log.columns else 'N/A'
        male_ratio = df_log["sex"].eq("‡∏ä‡∏≤‡∏¢").mean() * 100 if 'sex' in df_log.columns else 'N/A'

        col1_kpi.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏Ñ‡∏™‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", f"{total_cases:,}")
        col2_kpi.metric("‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏Ñ‡∏™‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å (Fatal)", f"{fatal_ratio:.1f}%")
        col3_kpi.metric("‡∏≠‡∏≤‡∏¢‡∏∏‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢", f"{avg_age:.1f}" if isinstance(avg_age, (int,float)) else avg_age)
        # col4_kpi.metric("‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏û‡∏®‡∏ä‡∏≤‡∏¢", f"{male_ratio:.1f}%" if isinstance(male_ratio, (int,float)) else male_ratio)


        # --- Charts ---
        st.markdown("---")
        chart_col1, chart_col2 = st.columns(2)

        # 1. Severity Distribution (Pie Chart)
        with chart_col1:
            st.markdown("##### ü©∏ ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á")
            severity_counts = df_log['predicted_severity'].value_counts()
            # Ensure correct order and colors
            severity_order = ["‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ô‡πâ‡∏≠‡∏¢", "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á", "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å"]
            severity_counts = severity_counts.reindex(severity_order, fill_value=0)
            colors_ordered = [triage_color.get(level, "#CCCCCC") for level in severity_order]

            if not severity_counts.empty:
                fig1, ax1 = plt.subplots(figsize=(4, 4))
                ax1.pie(severity_counts, labels=severity_counts.index, autopct='%1.1f%%',
                        startangle=90, colors=colors_ordered,
                        textprops={'fontsize': 9})
                ax1.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
                st.pyplot(fig1)
            else:
                st.caption("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")


        # 2. Cases over Time (Line Chart) - Requires 'timestamp'
        with chart_col2:
            st.markdown("##### üìà ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏Ñ‡∏™‡∏ï‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤")
            if 'timestamp' in df_log.columns:
                 df_log['date'] = df_log['timestamp'].dt.date
                 cases_over_time = df_log.groupby('date').size()
                 if not cases_over_time.empty:
                      st.line_chart(cases_over_time)
                 else:
                      st.caption("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
            else:
                 st.caption("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ß‡∏•‡∏≤ (timestamp)")


        # --- Risk Factor Analysis ---
        st.markdown("---")
        st.markdown("### ‚ùó ‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏™ '‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å'")
        risk_cols_log = [f"risk{i}" for i in range(1, 6) if f"risk{i}" in df_log.columns]
        risk_cols_log.append('head_injury') # Include head injury
        if 'is_night' in df_log.columns: risk_cols_log.append('is_night')


        fatal_cases = df_log[df_log["predicted_severity"] == "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å"]
        if not fatal_cases.empty and risk_cols_log:
             risk_counts_fatal = fatal_cases[risk_cols_log].sum().sort_values(ascending=False)
             # Map coded risk names to readable names if possible
             risk_display_names = {
                 "risk1": "‡∏î‡∏∑‡πà‡∏°‡πÅ‡∏≠‡∏•‡∏Å‡∏≠‡∏Æ‡∏≠‡∏•‡πå", "risk2": "‡πÉ‡∏ä‡πâ‡∏¢‡∏≤‡πÄ‡∏™‡∏û‡∏ï‡∏¥‡∏î", "risk3": "‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡πÄ‡∏Ç‡πá‡∏°‡∏Ç‡∏±‡∏î",
                 "risk4": "‡πÑ‡∏°‡πà‡∏™‡∏ß‡∏°‡∏´‡∏°‡∏ß‡∏Å", "risk5": "‡πÉ‡∏ä‡πâ‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå",
                 "head_injury": "‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡∏®‡∏µ‡∏£‡∏©‡∏∞", "is_night": "‡πÄ‡∏Å‡∏¥‡∏î‡∏Å‡∏•‡∏≤‡∏á‡∏Ñ‡∏∑‡∏ô"
             }
             risk_counts_fatal.index = risk_counts_fatal.index.map(risk_display_names).fillna(risk_counts_fatal.index)

             if not risk_counts_fatal.empty:
                 fig3, ax3 = plt.subplots(figsize=(6, 3))
                 sns.barplot(x=risk_counts_fatal.values, y=risk_counts_fatal.index, ax=ax3, palette="viridis")
                 ax3.set_xlabel("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏Ñ‡∏™")
                 ax3.set_ylabel("‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á")
                 st.pyplot(fig3)
             else:
                  st.caption("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏™‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å")

        else:
             st.caption("‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏Ñ‡∏™ '‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å' ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á")


         # --- Insights & Recommendations ---
        st.markdown("---")
        st.markdown("### üí° ‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡πÄ‡∏ä‡∏¥‡∏á‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå")
        # Example insights based on data
        if fatal_ratio > 10: # Example threshold
             st.warning("üö® ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏Ñ‡∏™ '‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å' ‡∏Ñ‡πà‡∏≠‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡∏™‡∏π‡∏á: ‡∏Ñ‡∏ß‡∏£‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå Triage ‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏±‡∏î‡∏™‡∏£‡∏£‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏´‡πâ‡∏≠‡∏á‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°")
        if not risk_counts_fatal.empty:
             top_risk = risk_counts_fatal.index[0]
             st.info(f"üìå ‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏™ '‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å' ‡∏Ñ‡∏∑‡∏≠ '{top_risk}': ‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏£‡∏ì‡∏£‡∏á‡∏Ñ‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏ï‡∏£‡∏Å‡∏≤‡∏£‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ô‡∏µ‡πâ")

    else: # If df_log is None or empty
        st.info("‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÉ‡∏ô‡πÅ‡∏ó‡πá‡∏ö 'Clinical Risk Prediction' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà")

st.markdown("---")
st.markdown("Developed by AI for Road Safety | Data Source: Injury Surveillance (IS) - MOPH")
