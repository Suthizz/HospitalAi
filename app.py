# -*- coding: utf-8 -*-
import os
import json
import joblib
import numpy as np
import pandas as pd
import streamlit as st
from catboost import CatBoostClassifier # Needed even when loading model
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder # Needed for preprocessing
import matplotlib.font_manager as fm

# ----------------------------------------------------------
# ‚öôÔ∏è Page Setup (FIXED: Must be the FIRST Streamlit command)
# ----------------------------------------------------------
st.set_page_config(layout="wide", page_title="Road Accident AI Decision Support", page_icon="üè•")
st.title("üè• Hospital AI Decision Support System")


# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ matplotlib ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÑ‡∏î‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
plt.style.use('dark_background')
plt.rcParams['figure.figsize'] = (6, 4)

# Configure matplotlib to support Thai font
# Use font_manager to find a font that supports Thai characters
thai_font_name = None
try:
    # Rebuild font cache if necessary, but can be slow
    # fm._load_fontmanager(try_read_cache=False) # Use this if fonts still not found after packages.txt
    
    # Find the best available Thai font
    thai_fonts = ['Loma', 'Sarabun', 'TH Sarabun New', 'Kinnari', 'Garuda', 'Leelawadee', 'Tahoma']
    font_list = [f.name for f in fm.fontManager.ttflist]
    
    for font in thai_fonts:
        if font in font_list:
            thai_font_name = font
            break

    if thai_font_name:
        plt.rcParams['font.family'] = thai_font_name
        # st.caption(f"‚úÖ Using Thai font: {plt.rcParams['font.family']}") # Uncomment for debugging
    else:
        st.warning("‚ö†Ô∏è No suitable Thai font found (e.g., Loma, Sarabun). Thai characters in graphs might not display correctly.")
        plt.rcParams['font.family'] = 'DejaVu Sans'
    
    plt.rcParams['font.sans-serif'] = [thai_font_name if thai_font_name else 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False # Allow minus sign

except Exception as e:
     st.warning(f"‚ö†Ô∏è Error setting Thai font: {e}. Graphs might show garbled text.")


# ----------------------------------------------------------
# üì¶ Load Models + Configs (FIXED: Removed st.write from cache)
# ----------------------------------------------------------

@st.cache_resource
def load_all():
    """Loads models and returns them along with status messages."""
    loaded_items = {}
    msgs = [] # List to store status messages
    
    st.write("‚è≥ Attempting to Load Models and Configurations...") # This one is ok as it's informational before loading

    # üîπ CatBoost Model
    try:
        model = joblib.load("predict_catboost_multi.pkl")
        loaded_items["model"] = model
        msgs.append("‚úÖ Clinical Severity Model (predict_catboost_multi.pkl) Loaded.")
    except Exception as e:
        loaded_items["model"] = None
        msgs.append(f"‚ùå Clinical Severity Model (predict_catboost_multi.pkl) NOT FOUND. (Error: {e}) -> Prediction will not work.")

    # üîπ Encoders / Features / K-Means / Apriori
    try:
        encoders = joblib.load("encoders_multi.pkl")
        loaded_items["encoders"] = encoders
        msgs.append("‚úÖ Encoders (encoders_multi.pkl) Loaded.")
    except Exception as e:
        loaded_items["encoders"] = None
        msgs.append(f"‚ö†Ô∏è Encoders (encoders_multi.pkl) NOT FOUND. (Error: {e}) -> Preprocessing might fail.")

    try:
        with open("features_multi.json", "r", encoding="utf-8") as f: 
            features = json.load(f)
        loaded_items["features"] = features
        msgs.append("‚úÖ Features List (features_multi.json) Loaded.")
    except Exception as e:
        loaded_items["features"] = ['age', 'sex', 'is_night', 'head_injury', 'mass_casualty', 'risk1', 'risk2', 'risk3', 'risk4', 'risk5', 'cannabis', 'amphetamine', 'drugs', 'activity', 'aplace', 'prov']
        msgs.append(f"‚ö†Ô∏è Features List (features_multi.json) NOT FOUND. (Error: {e}) -> Using default list.")

    try:
        kmeans = joblib.load("kmeans_cluster_model.pkl")
        scaler = joblib.load("scaler_cluster.pkl")
        loaded_items["kmeans"] = kmeans
        loaded_items["scaler"] = scaler
        msgs.append("‚úÖ K-Means Cluster Model and Scaler Loaded.")
    except Exception as e:
        loaded_items["kmeans"], loaded_items["scaler"] = None, None
        msgs.append(f"‚ö†Ô∏è K-Means Cluster Model or Scaler NOT FOUND. (Error: {e}) -> Clustering unavailable.")

    try:
        rules_minor = joblib.load("apriori_rules_minor.pkl")
        rules_severe = joblib.load("apriori_rules_severe.pkl")
        rules_fatal = joblib.load("apriori_rules_fatal.pkl")
        loaded_items["rules_minor"] = rules_minor
        loaded_items["rules_severe"] = rules_severe
        loaded_items["rules_fatal"] = rules_fatal
        msgs.append("‚úÖ Apriori Association Rules Loaded.")
    except Exception as e:
        loaded_items["rules_minor"], loaded_items["rules_severe"], loaded_items["rules_fatal"] = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()
        msgs.append(f"‚ö†Ô∏è Apriori Association Rules NOT FOUND. (Error: {e}) -> Risk association unavailable.")

    return loaded_items, msgs

# ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î
loaded_items, load_messages = load_all()

# --- Display Loading Status (FIXED: Moved expander outside cache) ---
with st.expander("üìÇ ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•", expanded=False):
    for msg in load_messages:
        if "‚úÖ" in msg:
            st.caption(msg)
        else:
            st.caption(f":warning: {msg}")

# Assign loaded items to variables
model = loaded_items.get("model")
encoders = loaded_items.get("encoders")
features = loaded_items.get("features")
kmeans = loaded_items.get("kmeans")
scaler = loaded_items.get("scaler")
rules_minor = loaded_items.get("rules_minor")
rules_severe = loaded_items.get("rules_severe")
rules_fatal = loaded_items.get("rules_fatal")


# ----------------------------------------------------------
# üß© Manual Mappings
# ----------------------------------------------------------
activity_mapping = {
    "0": "‡πÄ‡∏î‡∏¥‡∏ô‡πÄ‡∏ó‡πâ‡∏≤", "1": "‡πÇ‡∏î‡∏¢‡∏™‡∏≤‡∏£‡∏û‡∏≤‡∏´‡∏ô‡∏∞‡∏™‡∏≤‡∏ò‡∏≤‡∏£‡∏ì‡∏∞", "2": "‡πÇ‡∏î‡∏¢‡∏™‡∏≤‡∏£‡∏û‡∏≤‡∏´‡∏ô‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•",
    "3": "‡∏Ç‡∏±‡∏ö‡∏Ç‡∏µ‡πà‡∏û‡∏≤‡∏´‡∏ô‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•", "4": "‡∏ó‡∏≥‡∏á‡∏≤‡∏ô", "5": "‡πÄ‡∏•‡πà‡∏ô‡∏Å‡∏µ‡∏¨‡∏≤", "6": "‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏≠‡∏∑‡πà‡∏ô ‡πÜ"
}
aplace_mapping = {
    "10": "‡∏ö‡πâ‡∏≤‡∏ô‡∏û‡∏±‡∏Å‡∏≠‡∏≤‡∏®‡∏±‡∏¢", "11": "‡∏ñ‡∏ô‡∏ô/‡∏ó‡∏≤‡∏á‡∏´‡∏•‡∏ß‡∏á", "12": "‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô",
    "13": "‡πÇ‡∏£‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô/‡∏™‡∏ñ‡∏≤‡∏ö‡∏±‡∏ô‡∏®‡∏∂‡∏Å‡∏©‡∏≤", "14": "‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏ò‡∏≤‡∏£‡∏ì‡∏∞", "15": "‡∏≠‡∏∑‡πà‡∏ô ‡πÜ"
}
prov_mapping = {
    "10": "‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£", "20": "‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà", "30": "‡∏Ç‡∏≠‡∏ô‡πÅ‡∏Å‡πà‡∏ô",
    "40": "‡∏†‡∏π‡πÄ‡∏Å‡πá‡∏ï", "50": "‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤", "60": "‡∏™‡∏á‡∏Ç‡∏•‡∏≤", "99": "‡∏≠‡∏∑‡πà‡∏ô ‡πÜ"
}
# Add default mapping for potential 'Unknown' or missing keys
activity_mapping.setdefault("Unknown", "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏")
aplace_mapping.setdefault("Unknown", "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏")
prov_mapping.setdefault("Unknown", "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏")

severity_map = {0: "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ô‡πâ‡∏≠‡∏¢", 1: "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á", 2: "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å"}
advice_map = {
    "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ô‡πâ‡∏≠‡∏¢": "‡∏î‡∏π‡πÅ‡∏•‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡πÄ‡∏ù‡πâ‡∏≤‡∏£‡∏∞‡∏ß‡∏±‡∏á‡∏ã‡πâ‡∏≥‡∏ó‡∏∏‡∏Å 15‚Äì30 ‡∏ô‡∏≤‡∏ó‡∏µ",
    "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á": "‡∏™‡πà‡∏á‡∏ï‡∏£‡∏ß‡∏à‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏£‡∏ô‡πâ‡∏≥ / ‡∏¢‡∏≤‡πÅ‡∏Å‡πâ‡∏õ‡∏ß‡∏î / ‡πÄ‡∏ù‡πâ‡∏≤‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏ä‡∏µ‡∏û‡πÉ‡∏Å‡∏•‡πâ‡∏ä‡∏¥‡∏î",
    "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å": "‡πÅ‡∏à‡πâ‡∏á‡∏ó‡∏µ‡∏°‡∏™‡∏´‡∏™‡∏≤‡∏Ç‡∏≤ ‡πÄ‡∏õ‡∏¥‡∏î‡∏ó‡∏≤‡∏á‡πÄ‡∏î‡∏¥‡∏ô‡∏´‡∏≤‡∏¢‡πÉ‡∏à ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏´‡πâ‡∏≠‡∏á‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏™‡πà‡∏á‡∏ï‡πà‡∏≠‡∏î‡πà‡∏ß‡∏ô"
}
triage_color = {
    "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ô‡πâ‡∏≠‡∏¢": "#4CAF50", "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á": "#FFC107", "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å": "#F44336"
}

# ----------------------------------------------------------
# üß© Preprocess Function
# ----------------------------------------------------------
def preprocess_input(data_dict, loaded_encoders, expected_features, activity_map, aplace_map, prov_map):
    """Preprocesses user input dictionary based on loaded encoders and features."""
    if not expected_features:
        st.error("Feature list is empty. Cannot preprocess.")
        return None
    if loaded_encoders is None:
         st.warning("Encoders not loaded. Categorical features might not be processed correctly.")
         loaded_encoders = {} # Use an empty dict to avoid errors

    df = pd.DataFrame([data_dict])
    
    # Map display values back to codes before encoding
    reverse_activity = {v: k for k, v in activity_map.items()}
    reverse_aplace = {v: k for k, v in aplace_map.items()}
    reverse_prov = {v: k for k, v in prov_map.items()}

    # Use .get() with a default 'Unknown' code if the display value isn't found
    df['activity'] = df['activity'].apply(lambda x: reverse_activity.get(x, "Unknown"))
    df['aplace'] = df['aplace'].apply(lambda x: reverse_aplace.get(x, "Unknown"))
    df['prov'] = df['prov'].apply(lambda x: reverse_prov.get(x, "Unknown"))

    # Reindex first to ensure all expected columns are present
    df = df.reindex(columns=expected_features, fill_value=0) # Use 0 as default fill

    # Clean potential string issues and fill NaNs *after* reindexing
    clean_values = ["None", "N/A", "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏", "N", "nan", "NaN", "", " "]
    df = df.replace(clean_values, "Unknown") # Replace various missing representations with 'Unknown'
    df = df.fillna("Unknown") # Fill any actual NaNs

    # Encode categorical features using loaded encoders
    for col, le in loaded_encoders.items():
        if col in df.columns and isinstance(le, LabelEncoder): # Check if encoder is valid
            df[col] = df[col].astype(str) # Ensure string type before transform
            
            unknown_class_index = 0 # Default index if 'Unknown' not in classes
            if "Unknown" in le.classes_:
                try:
                  unknown_class_index = int(le.transform(["Unknown"])[0])
                except ValueError:
                  pass # Should not happen

            df[col] = df[col].apply(lambda x: int(le.transform([x])[0]) if x in le.classes_ else unknown_class_index)
        elif col in df.columns: # Fallback if encoder invalid or missing
             df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)


    # --- Create Engineered Features (must match training - check feature list) ---
    if 'age' in df.columns:
        df['age'] = pd.to_numeric(df['age'], errors='coerce').fillna(0)
        if "age_group_60plus" in expected_features:
             df["age_group_60plus"] = (df["age"] >= 60).astype(int)

    risk_cols_in_features = [f"risk{i}" for i in range(1, 6) if f"risk{i}" in expected_features]
    if "risk_count" in expected_features:
        for r_col in risk_cols_in_features:
            if r_col in df.columns:
                 df[r_col] = pd.to_numeric(df[r_col], errors='coerce').fillna(0)
            else:
                 df[r_col] = 0
        df["risk_count"] = df[risk_cols_in_features].sum(axis=1)

    if 'is_night' in df.columns:
        df['is_night'] = pd.to_numeric(df['is_night'], errors='coerce').fillna(0)
        if "night_flag" in expected_features:
            df["night_flag"] = df["is_night"].astype(int)
    elif "night_flag" in expected_features:
         df["night_flag"] = 0

    # Ensure all columns are numeric at the end
    for col in df.columns:
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)

    # Final check: Ensure column order matches exactly
    try:
        df = df[expected_features]
    except KeyError as e:
        missing_keys = set(expected_features) - set(df.columns)
        st.error(f"Mismatch in expected features during final step. Missing: {missing_keys}. Error: {e}")
        return None
    except Exception as e:
        st.error(f"An unexpected error occurred ensuring final feature order: {e}")
        return None

    return df

# ----------------------------------------------------------
# üìÑ Streamlit App Layout
# ----------------------------------------------------------

# Initialize session state for form inputs if not already done
# (Using keys based on the input variable name for simplicity)
defaults = {
    'age': 30, 'sex': "‡∏ä‡∏≤‡∏¢", 'is_night': False, 'head_injury': False,
    'mass_casualty': False, 
    'activity': list(activity_mapping.values())[0], # Default to "‡πÄ‡∏î‡∏¥‡∏ô‡πÄ‡∏ó‡πâ‡∏≤"
    'aplace': list(aplace_mapping.values())[0], # Default to "‡∏ö‡πâ‡∏≤‡∏ô‡∏û‡∏±‡∏Å‡∏≠‡∏≤‡∏®‡∏±‡∏¢"
    'prov': list(prov_mapping.values())[0], # Default to "‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£"
    'risk1': False, 'risk2': False, 'risk3': False, 'risk4': False, 'risk5': False,
    'cannabis': False, 'amphetamine': False, 'drugs': False,
    'predicted_severity': "‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
}
for key, value in defaults.items():
    if key not in st.session_state:
        st.session_state[key] = value


# Function to reset form inputs and clear log
def reset_all_data():
    # Reset form inputs in session state
    for key, value in defaults.items():
        st.session_state[key] = value
    
    st.session_state.predicted_severity = "‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•" # Reset prediction explicitly

    # Clear the prediction log file
    log_file = "prediction_log.csv"
    if os.path.exists(log_file):
        try:
            os.remove(log_file)
            st.success("‚úÖ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÅ‡∏•‡∏∞ Log ‡∏ñ‡∏π‡∏Å‡∏•‡πâ‡∏≤‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
        except Exception as e:
            st.error(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå Log: {e}")
    else:
        st.info("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Log ‡πÉ‡∏´‡πâ‡∏•‡πâ‡∏≤‡∏á")
    
    # Clear processed data for tabs
    if 'processed_input_for_tabs' in st.session_state:
        st.session_state.processed_input_for_tabs = None
    if 'raw_input_for_tabs' in st.session_state:
        st.session_state.raw_input_for_tabs = {}
    if 'submit_pressed' in st.session_state:
        st.session_state.submit_pressed = False


# ----------------------------------------------------------
# üß† TAB 1 ‚Äî Clinical Risk Prediction
# ----------------------------------------------------------
tab1, tab2, tab3, tab4 = st.tabs([
    "üß† Clinical Risk Prediction",
    "üë• Cluster Insight",
    "üß© Risk Association",
    "üìä Clinical Summary Dashboard"
])

with tab1:
    st.subheader("üß† Clinical Severity Prediction")
    st.caption("‡∏£‡∏∞‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå")
    
    if model is None or features is None or encoders is None:
        st.error("‚ùå ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏´‡∏•‡∏±‡∏Å (CatBoost), Encoders ‡∏´‡∏£‡∏∑‡∏≠ Features list ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå")
    else:
        with st.form("prediction_form"):
            col1, col2, col3 = st.columns(3)
            with col1:
                # Use session state keys for inputs
                age = st.slider("‡∏≠‡∏≤‡∏¢‡∏∏", 0, 100, key='age')
                sex = st.radio("‡πÄ‡∏û‡∏®", ["‡∏ä‡∏≤‡∏¢", "‡∏´‡∏ç‡∏¥‡∏á"], key='sex')
                is_night = st.checkbox("‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Å‡∏•‡∏≤‡∏á‡∏Ñ‡∏∑‡∏ô", key='is_night')
            with col2:
                head_injury = st.checkbox("‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡∏ó‡∏µ‡πà‡∏®‡∏µ‡∏£‡∏©‡∏∞", key='head_injury')
                mass_casualty = st.checkbox("‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏´‡∏°‡∏π‡πà (Mass Casualty)", key='mass_casualty')
                activity = st.selectbox("‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°", list(activity_mapping.values()), key='activity')
            with col3:
                aplace = st.selectbox("‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏", list(aplace_mapping.values()), key='aplace')
                prov = st.selectbox("‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î", list(prov_mapping.values()), key='prov')
                
                st.markdown("**‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á:**")
                risk_col1, risk_col2, risk_col3 = st.columns(3)
                with risk_col1:
                    risk1 = st.checkbox("Risk 1: ‡πÑ‡∏°‡πà‡∏™‡∏ß‡∏°‡∏´‡∏°‡∏ß‡∏Å/‡πÄ‡∏Ç‡πá‡∏°‡∏Ç‡∏±‡∏î", key='risk1', help="‡πÑ‡∏°‡πà‡∏™‡∏ß‡∏°‡∏´‡∏°‡∏ß‡∏Å‡∏ô‡∏¥‡∏£‡∏†‡∏±‡∏¢ / ‡πÄ‡∏Ç‡πá‡∏°‡∏Ç‡∏±‡∏î‡∏ô‡∏¥‡∏£‡∏†‡∏±‡∏¢")
                    risk2 = st.checkbox("Risk 2: ‡∏Ç‡∏±‡∏ö‡πÄ‡∏£‡πá‡∏ß/‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ó", key='risk2')
                    risk3 = st.checkbox("Risk 3: ‡πÄ‡∏°‡∏≤ / ‡∏î‡∏∑‡πà‡∏°‡∏™‡∏∏‡∏£‡∏≤", key='risk3')
                with risk_col2:
                    risk4 = st.checkbox("Risk 4: ‡∏ú‡∏π‡πâ‡∏™‡∏π‡∏á‡∏≠‡∏≤‡∏¢‡∏∏ / ‡πÄ‡∏î‡πá‡∏Å‡πÄ‡∏•‡πá‡∏Å", key='risk4')
                    risk5 = st.checkbox("Risk 5: ‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á", key='risk5')
                
                st.markdown("**‡∏™‡∏≤‡∏£‡πÄ‡∏™‡∏û‡∏ï‡∏¥‡∏î:**")
                drug_col1, drug_col2, drug_col3 = st.columns(3)
                with drug_col1:
                    cannabis = st.checkbox("‡∏Å‡∏±‡∏ç‡∏ä‡∏≤", key='cannabis')
                with drug_col2:
                    amphetamine = st.checkbox("‡πÅ‡∏≠‡∏°‡πÄ‡∏ü‡∏ï‡∏≤‡∏°‡∏µ‡∏ô", key='amphetamine')
                with drug_col3:
                    drugs = st.checkbox("‡∏¢‡∏≤‡∏≠‡∏∑‡πà‡∏ô ‡πÜ", key='drugs')

            col_buttons = st.columns(2)
            with col_buttons[0]:
                submit_button = st.form_submit_button("‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á")
            with col_buttons[1]:
                # Use the reset function here
                clear_button = st.form_submit_button("‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", on_click=reset_all_data) 

        if submit_button:
            st.session_state.submit_pressed = True # Mark submission
            
            # 1. ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö Input Data (using session state values)
            input_data = {
                "age": st.session_state.age,
                "sex": '1' if st.session_state.sex == "‡∏ä‡∏≤‡∏¢" else '2', # Map back to '1'/'2' code
                "is_night": int(st.session_state.is_night),
                "head_injury": int(st.session_state.head_injury),
                "mass_casualty": int(st.session_state.mass_casualty),
                "risk1": int(st.session_state.risk1), "risk2": int(st.session_state.risk2), "risk3": int(st.session_state.risk3),
                "risk4": int(st.session_state.risk4), "risk5": int(st.session_state.risk5),
                "cannabis": int(st.session_state.cannabis), "amphetamine": int(st.session_state.amphetamine), "drugs": int(st.session_state.drugs),
                "activity": st.session_state.activity, # Pass display value
                "aplace": st.session_state.aplace,     # Pass display value
                "prov": st.session_state.prov          # Pass display value
            }
            
            # Store raw input (using display values) for other tabs
            st.session_state.raw_input_for_tabs = {
                "age": st.session_state.age, "sex": st.session_state.sex, "is_night": st.session_state.is_night, 
                "head_injury": st.session_state.head_injury, "mass_casualty": st.session_state.mass_casualty, 
                "risk1": st.session_state.risk1, "risk2": st.session_state.risk2, "risk3": st.session_state.risk3, 
                "risk4": st.session_state.risk4, "risk5": st.session_state.risk5, "cannabis": st.session_state.cannabis, 
                "amphetamine": st.session_state.amphetamine, "drugs": st.session_state.drugs, 
                "activity": st.session_state.activity, "aplace": st.session_state.aplace, "prov": st.session_state.prov
            }

            # 2. Preprocess
            X_input = preprocess_input(input_data, encoders, features, activity_mapping, aplace_mapping, prov_mapping)
            st.session_state.processed_input_for_tabs = X_input # Store processed input

            # 3. Predict
            if X_input is not None:
                try:
                    probs = model.predict_proba(X_input)[0]
                    pred_class = int(np.argmax(probs))
                    current_label = severity_map.get(pred_class, "‡πÑ‡∏°‡πà‡∏ó‡∏£‡∏≤‡∏ö")
                    color = triage_color.get(current_label, "#2196F3")

                    # Update session state with the prediction result
                    st.session_state.predicted_severity = current_label

                    # 4. ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
                    st.subheader("üî• ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á")
                    st.markdown(f"<h3 style='color:{color}'>{current_label}</h3>", unsafe_allow_html=True)
                    st.info(f"üí° ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô: {advice_map.get(current_label, '‡πÑ‡∏°‡πà‡∏ó‡∏£‡∏≤‡∏ö‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á')}")
                    st.caption(f"üß† ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö: {probs[pred_class]*100:.1f}%")
                    # Optional: Show probabilities for all classes
                    with st.expander("‡∏î‡∏π‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏£‡∏∞‡∏î‡∏±‡∏ö"):
                        prob_df = pd.DataFrame({
                            "‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á": [severity_map.get(i, f"Class {i}") for i in range(len(probs))],
                            "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô": [f"{p*100:.1f}%" for p in probs]
                        })
                        st.dataframe(prob_df, hide_index=True)


                    # 5. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Prediction Log (For Dashboard)
                    log_file = "prediction_log.csv"
                    try:
                        log_entry = {
                            "timestamp": pd.Timestamp.now(tz='Asia/Bangkok').strftime('%Y-%m-%d %H:%M:%S %Z'),
                            "age": st.session_state.age,
                            "sex": st.session_state.sex, # Log display value
                            "predicted_severity": current_label,
                            "prov": st.session_state.prov, # Log display value
                            "is_night": int(st.session_state.is_night),
                            "risk1": int(st.session_state.risk1),
                            "risk2": int(st.session_state.risk2),
                            "risk3": int(st.session_state.risk3),
                            "risk4": int(st.session_state.risk4),
                            "risk5": int(st.session_state.risk5),
                            "head_injury": int(st.session_state.head_injury),
                            "cannabis": int(st.session_state.cannabis),
                            "amphetamine": int(st.session_state.amphetamine),
                            "drugs": int(st.session_state.drugs)
                        }
                        new_row = pd.DataFrame([log_entry])
                        
                        write_header = not os.path.exists(log_file)
                        new_row.to_csv(log_file, mode="a", index=False, header=write_header, encoding='utf-8-sig')
                        st.success("üìÅ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö Log ‡πÅ‡∏•‡πâ‡∏ß")
                    
                    except Exception as log_e:
                        st.warning(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Log: {log_e}")

                except Exception as e:
                    st.error(f"‚ùå Error ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢: {e}")
            else:
                st.error("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Input ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÑ‡∏î‡πâ")

# ----------------------------------------------------------
# üë• TAB 2 ‚Äî K-Means Cluster Analysis
# ----------------------------------------------------------
with tab2:
    st.subheader("üë• Patient Segmentation (K-Means)")
    st.caption("‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ú‡∏π‡πâ‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏™‡∏£‡∏£‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÄ‡∏ä‡∏¥‡∏á‡∏£‡∏∏‡∏Å")

    if not st.session_state.get('submit_pressed', False):
        st.info("üïê ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÉ‡∏ô‡πÅ‡∏ó‡πá‡∏ö 'Clinical Risk Prediction' ‡∏Å‡πà‡∏≠‡∏ô")
    elif kmeans is None or scaler is None:
        st.warning("‚ö†Ô∏è ‡πÇ‡∏°‡πÄ‡∏î‡∏• K-Means / Scaler ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
    elif st.session_state.get('processed_input_for_tabs') is None:
        st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏≤‡∏Å‡πÅ‡∏ó‡πá‡∏ö‡πÅ‡∏£‡∏Å")
    else:
        # --- Display Patient Summary (using raw_input_for_tabs) ---
        st.markdown("### üßæ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö")
        raw_input = st.session_state.get('raw_input_for_tabs', {})
        summary_cols = st.columns(3)
        summary_cols[0].metric("‡∏≠‡∏≤‡∏¢‡∏∏", f"{raw_input.get('age', 'N/A')} ‡∏õ‡∏µ")
        summary_cols[1].metric("‡πÄ‡∏û‡∏®", raw_input.get('sex', 'N/A'))
        summary_cols[2].metric("‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á", st.session_state.get('prediction_label', 'N/A'))

        risk_summary = []
        if raw_input.get('risk1'): risk_summary.append("‡∏î‡∏∑‡πà‡∏°‡πÅ‡∏≠‡∏•‡∏Å‡∏≠‡∏Æ‡∏≠‡∏•‡πå")
        if raw_input.get('risk2'): risk_summary.append("‡πÉ‡∏ä‡πâ‡∏¢‡∏≤‡πÄ‡∏™‡∏û‡∏ï‡∏¥‡∏î(‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ)")
        if raw_input.get('risk3'): risk_summary.append("‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡πÄ‡∏Ç‡πá‡∏°‡∏Ç‡∏±‡∏î")
        if raw_input.get('risk4'): risk_summary.append("‡πÑ‡∏°‡πà‡∏™‡∏ß‡∏°‡∏´‡∏°‡∏ß‡∏Å‡∏ô‡∏¥‡∏£‡∏†‡∏±‡∏¢")
        if raw_input.get('risk5'): risk_summary.append("‡πÉ‡∏ä‡πâ‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå‡∏Ç‡∏ì‡∏∞‡∏Ç‡∏±‡∏ö")
        if raw_input.get('head_injury'): risk_summary.append("‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡∏®‡∏µ‡∏£‡∏©‡∏∞")
        if raw_input.get('cannabis'): risk_summary.append("‡∏Å‡∏±‡∏ç‡∏ä‡∏≤")
        if raw_input.get('amphetamine'): risk_summary.append("‡∏¢‡∏≤‡∏ö‡πâ‡∏≤")
        if raw_input.get('drugs'): risk_summary.append("‡∏¢‡∏≤‡∏≠‡∏∑‡πà‡∏ô ‡πÜ")
        if raw_input.get('is_night'): risk_summary.append("‡πÄ‡∏Å‡∏¥‡∏î‡∏Å‡∏•‡∏≤‡∏á‡∏Ñ‡∏∑‡∏ô")
        st.markdown(f"**‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÄ‡∏î‡πà‡∏ô:** {', '.join(risk_summary) if risk_summary else '-'}")
        st.markdown("---")

        # --- Perform Clustering (using processed_input_for_tabs) ---
        try:
            X_input_processed = st.session_state.processed_input_for_tabs
            
            cluster_features_used = None
            if hasattr(scaler, "feature_names_in_"):
                cluster_features_used = scaler.feature_names_in_
            elif hasattr(scaler, 'n_features_in_'):
                 st.warning("Scaler object lacks explicit feature names. Attempting to infer feature list.")
                 # Infer features based on notebook's cluster_cols
                 cluster_cols_base = ["age", "sex", "is_night", "head_injury", "risk1", "risk2", "risk3", "risk4", "risk5", "cannabis", "amphetamine", "drugs"]
                 # Check if these columns exist in the processed input
                 if all(c in X_input_processed.columns for c in cluster_cols_base):
                      cluster_features_used = cluster_cols_base
                 else:
                      st.error(f"Cannot infer clustering features. Scaler expected {scaler.n_features_in_}, but base columns not found in processed data.")
            else:
                 st.error("Cannot determine features expected by the scaler. Clustering aborted.")

            if cluster_features_used:
                X_cluster_input = X_input_processed.copy()
                # Ensure all required columns exist, fill missing with 0
                for col in cluster_features_used:
                    if col not in X_cluster_input.columns:
                        X_cluster_input[col] = 0
                
                # Select and reorder columns
                try:
                    X_cluster_input = X_cluster_input[cluster_features_used]
                    
                    X_scaled = scaler.transform(X_cluster_input)
                    cluster_label = int(kmeans.predict(X_scaled)[0])

                    # Cluster Descriptions (Based on Notebook Analysis)
                    cluster_desc = {
                        0: "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ/‡πÄ‡∏û‡∏®‡∏ä‡∏≤‡∏¢ (Cluster 0): ‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢‡∏™‡∏∏‡∏î, ‡∏°‡∏±‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏≤‡∏¢, ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡∏®‡∏µ‡∏£‡∏©‡∏∞‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á",
                        1: "‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏û‡∏®‡∏´‡∏ç‡∏¥‡∏á/‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ï‡πà‡∏≥ (Cluster 1): ‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢‡∏£‡∏≠‡∏á‡∏•‡∏á‡∏°‡∏≤, ‡∏°‡∏±‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏ç‡∏¥‡∏á, ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡∏Å‡∏•‡∏∏‡πà‡∏° 0",
                        2: "‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏¢‡∏≤‡πÄ‡∏™‡∏û‡∏ï‡∏¥‡∏î (Cluster 2): ‡∏û‡∏ö‡∏ô‡πâ‡∏≠‡∏¢, ‡∏°‡∏µ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏¢‡∏≤ (risk2, cannabis, amphetamine) ‡πÅ‡∏•‡∏∞‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡∏®‡∏µ‡∏£‡∏©‡∏∞‡∏™‡∏π‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î"
                    }

                    st.markdown(f"### üìä ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°: **Cluster {cluster_label}**")
                    st.info(f"**‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Å‡∏•‡∏∏‡πà‡∏° (‡πÇ‡∏î‡∏¢‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì):** {cluster_desc.get(cluster_label, '‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ô‡∏µ‡πâ')}")
                    st.caption("üí° ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô ‡πÅ‡∏•‡∏∞‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏Ñ‡∏°‡πÄ‡∏õ‡∏ç‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢")

                except KeyError as e:
                     st.error(f"Error selecting/ordering columns for scaler: {e}")
                except Exception as e:
                     st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏° K-Means: {e}")
            
        except Exception as e:
            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Clustering: {e}")


# ----------------------------------------------------------
# üß© TAB 3 ‚Äî Apriori Risk Association
# ----------------------------------------------------------
with tab3:
    st.subheader("üß© Risk Association Analysis (Apriori)")
    st.caption("‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡πÄ‡∏ä‡∏¥‡∏á‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢")

    if not st.session_state.get('submit_pressed', False):
        st.info("üïê ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÉ‡∏ô‡πÅ‡∏ó‡πá‡∏ö 'Clinical Risk Prediction' ‡∏Å‡πà‡∏≠‡∏ô")
    elif rules_minor is None and rules_severe is None and rules_fatal is None:
        st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Å‡∏é Apriori ‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ß‡πâ")
    else:
        # --- Display Patient Summary ---
        st.markdown("### üßæ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö")
        raw_input = st.session_state.get('raw_input_for_tabs', {})
        summary_cols = st.columns(3)
        summary_cols[0].metric("‡∏≠‡∏≤‡∏¢‡∏∏", f"{raw_input.get('age', 'N/A')} ‡∏õ‡∏µ")
        summary_cols[1].metric("‡πÄ‡∏û‡∏®", raw_input.get('sex', 'N/A'))
        summary_cols[2].metric("‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á", st.session_state.get('prediction_label', 'N/A'))

        risk_tags = []
        if raw_input.get('risk1'): risk_tags.append("‡∏î‡∏∑‡πà‡∏°‡πÅ‡∏≠‡∏•‡∏Å‡∏≠‡∏Æ‡∏≠‡∏•‡πå")
        if raw_input.get('risk2'): risk_tags.append("‡πÉ‡∏ä‡πâ‡∏¢‡∏≤‡πÄ‡∏™‡∏û‡∏ï‡∏¥‡∏î(‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ)")
        if raw_input.get('risk3'): risk_tags.append("‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡πÄ‡∏Ç‡πá‡∏°‡∏Ç‡∏±‡∏î")
        if raw_input.get('risk4'): risk_summary.append("‡πÑ‡∏°‡πà‡∏™‡∏ß‡∏°‡∏´‡∏°‡∏ß‡∏Å‡∏ô‡∏¥‡∏£‡∏†‡∏±‡∏¢")
        if raw_input.get('risk5'): risk_summary.append("‡πÉ‡∏ä‡πâ‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå‡∏Ç‡∏ì‡∏∞‡∏Ç‡∏±‡∏ö")
        if raw_input.get('head_injury'): risk_tags.append("‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡∏®‡∏µ‡∏£‡∏©‡∏∞")
        if raw_input.get('cannabis'): risk_tags.append("‡∏Å‡∏±‡∏ç‡∏ä‡∏≤")
        if raw_input.get('amphetamine'): risk_tags.append("‡∏¢‡∏≤‡∏ö‡πâ‡∏≤")
        if raw_input.get('drugs'): risk_tags.append("‡∏¢‡∏≤‡∏≠‡∏∑‡πà‡∏ô ‡πÜ")
        if raw_input.get('is_night'): risk_tags.append("‡πÄ‡∏Å‡∏¥‡∏î‡∏Å‡∏•‡∏≤‡∏á‡∏Ñ‡∏∑‡∏ô")
        st.markdown(f"**‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÄ‡∏î‡πà‡∏ô:** {', '.join(risk_tags) if risk_tags else '-'}")
        st.markdown("---")

        # --- Select and Display Relevant Rules ---
        st.markdown("### üîó ‡∏Å‡∏é‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á (Top 5 by Lift)")

        target_label = st.session_state.get('prediction_label', 'N/A')
        rules_df_to_show = None
        rules_title = f"‡∏Å‡∏é‡∏ó‡∏µ‡πà‡∏ô‡∏≥‡πÑ‡∏õ‡∏™‡∏π‡πà: {target_label}"

        is_valid_df = lambda df: isinstance(df, pd.DataFrame) and not df.empty

        if target_label == "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ô‡πâ‡∏≠‡∏¢" and is_valid_df(rules_minor):
            rules_df_to_show = rules_minor
        elif target_label == "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á" and is_valid_df(rules_severe):
            rules_df_to_show = rules_severe
        elif target_label == "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å" and is_valid_df(rules_fatal):
            rules_df_to_show = rules_fatal

        if rules_df_to_show is not None:
            st.markdown(f"**{rules_title}**")
            display_df = rules_df_to_show.head(5).copy()

            if 'antecedents' in display_df.columns:
                 display_df["‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ô‡∏≥ (Antecedents)"] = display_df["antecedents"].apply(decode_set)
            else:
                 display_df["‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ô‡∏≥ (Antecedents)"] = "N/A"

            if 'consequents' in display_df.columns:
                 display_df["‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (Consequents)"] = display_df["consequents"].apply(decode_set)
            else:
                 display_df["‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (Consequents)"] = "N/A"

            cols_to_display = ["‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ô‡∏≥ (Antecedents)", "‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (Consequents)"]
            rename_map = {"support": "Support", "confidence": "Confidence", "lift": "Lift"}
            for col, new_name in rename_map.items():
                if col in display_df.columns:
                    cols_to_display.append(new_name)
                    display_df = display_df.rename(columns={col: new_name})
            
            if "‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ô‡∏≥ (Antecedents)" in display_df.columns and "‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (Consequents)" in display_df.columns:
                # Display Top Rule Insight
                top_rule = display_df.iloc[0]
                st.markdown(
                    f"""
                    <div style='background-color:#262730;border-radius:10px;padding:12px;margin-bottom:10px; border: 1px solid #444;'>
                    üí° <b>Insight ‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢‡∏™‡∏∏‡∏î (Lift ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î):</b> 
                    <br>
                    ‡∏û‡∏ö‡∏ß‡πà‡∏≤‡∏ú‡∏π‡πâ‡∏ó‡∏µ‡πà‡∏°‡∏µ <b>{top_rule['‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ô‡∏≥ (Antecedents)']}</b>
                    <br>
                    ‡∏°‡∏µ‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏° <b>{top_rule['‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (Consequents)']}</b>
                    <br>
                    <small>(Confidence: {top_rule.get('Confidence', 0)*100:.1f}%, Lift = {top_rule.get('Lift', 0):.2f})</small>
                    </div>
                    """,
                    unsafe_allow_html=True
                )
                
                # Display Table
                st.dataframe(
                    display_df[cols_to_display],
                    use_container_width=True,
                    hide_index=True
                )
                
                # Display interpretation
                st.markdown("üìò **‡∏Å‡∏≤‡∏£‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°:**")
                st.markdown("- **Support:** ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ñ‡∏™‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ô‡∏≥‡πÅ‡∏•‡∏∞‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ô‡∏µ‡πâ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô")
                st.markdown("- **Confidence:** ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏Å‡∏¥‡∏î '‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå' ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏û‡∏ö '‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ô‡∏≥' ‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ")
                st.markdown("- **Lift > 1:** ‡∏ö‡πà‡∏á‡∏ä‡∏µ‡πâ‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏ô‡∏±‡∏¢‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ö‡∏±‡∏á‡πÄ‡∏≠‡∏¥‡∏ç) ‡∏¢‡∏¥‡πà‡∏á‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á‡∏¢‡∏¥‡πà‡∏á‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏Å‡∏±‡∏ô‡∏°‡∏≤‡∏Å")
            else:
                 st.error("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏é Apriori ‡πÑ‡∏î‡πâ (‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå antecedents/consequents ‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î)")

        else:
            st.info(f"üì≠ ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏é Apriori ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏£‡∏∞‡∏î‡∏±‡∏ö '{target_label}' ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏Å‡∏é‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤")


# ----------------------------------------------------------
# üìä TAB 4 ‚Äî Clinical Summary Dashboard
# ----------------------------------------------------------
with tab4:
    st.subheader("üìä Clinical Summary & Insights Dashboard")
    st.caption("‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏ú‡∏π‡πâ‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏ö AI ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡πÄ‡∏ä‡∏¥‡∏á‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå‡πÅ‡∏•‡∏∞‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•")

    log_file = "prediction_log.csv"
    df_log = None
    log_load_error = None

    # 1. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Log
    if os.path.exists(log_file):
        try:
            df_log = pd.read_csv(log_file, parse_dates=['timestamp'], encoding='utf-8-sig')
            df_log['timestamp'] = pd.to_datetime(df_log['timestamp'], errors='coerce').dt.tz_localize(None)
            df_log = df_log.dropna(subset=['timestamp'])

            if not df_log.empty:
                 st.success(f"üìÅ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Log ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(df_log):,} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
            else:
                 st.info("‡πÑ‡∏ü‡∏•‡πå Log ‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤ ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
                 df_log = None
        except pd.errors.EmptyDataError:
             st.info("‡πÑ‡∏ü‡∏•‡πå Log ‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤")
             df_log = None
        except Exception as e:
            log_load_error = f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Log ({LOG_FILE}): {e}"
            st.error(log_load_error)
            df_log = None
    else:
        st.info("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Log ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ (‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÉ‡∏ô‡πÅ‡∏ó‡πá‡∏ö‡πÅ‡∏£‡∏Å)")

    # 2. ‡∏õ‡∏∏‡πà‡∏° Reset (‡∏¢‡πâ‡∏≤‡∏¢‡∏°‡∏≤‡πÑ‡∏ß‡πâ‡πÉ‡∏ï‡πâ‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î)
    if st.button("üßπ ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Log ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (Reset Dashboard)"):
        if os.path.exists(log_file):
            try:
                os.remove(log_file)
                st.success("‚úÖ ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Log ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
                df_log = None
                st.rerun()
            except Exception as e:
                st.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå Log: {e}")
        else:
            st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå Log ‡πÉ‡∏´‡πâ‡∏•‡∏ö")

    st.markdown("---")

    # 3. Dashboard Content
    if df_log is not None and not df_log.empty:
        total_cases = len(df_log)

        # 3.1 KPI Overview
        st.markdown("### üí° ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå (KPI Overview)")
        col_kpi1, col_kpi2, col_kpi3 = st.columns(3)

        fatal_ratio = df_log["predicted_severity"].eq("‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å").mean() * 100 if "predicted_severity" in df_log.columns else 0
        avg_age = df_log["age"].mean() if 'age' in df_log.columns and pd.api.types.is_numeric_dtype(df_log['age']) else 'N/A'
        male_ratio = df_log["sex"].eq("‡∏ä‡∏≤‡∏¢").mean() * 100 if 'sex' in df_log.columns else 'N/A'

        col_kpi1.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏Ñ‡∏™‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", f"{total_cases:,}")
        col_kpi2.metric("‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏Ñ‡∏™‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å (Fatal)", f"{fatal_ratio:.1f}%")
        col_kpi3.metric("‡∏≠‡∏≤‡∏¢‡∏∏‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢", f"{avg_age:.1f}" if isinstance(avg_age, (int,float)) else avg_age)
        
        st.markdown("---")
        chart_col1, chart_col2 = st.columns(2)

        # 3.2 Severity Distribution (Pie Chart)
        with chart_col1:
            st.markdown("##### ü©∏ ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á")
            if 'predicted_severity' in df_log.columns:
                severity_counts = df_log['predicted_severity'].value_counts()
                severity_order = ["‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ô‡πâ‡∏≠‡∏¢", "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á", "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å"]
                severity_counts = severity_counts.reindex(severity_order, fill_value=0)
                colors_ordered = [triage_color.get(level, "#CCCCCC") for level in severity_order]

                if not severity_counts.empty and severity_counts.sum() > 0:
                    fig1, ax1 = plt.subplots(figsize=(4, 4))
                    ax1.pie(
                        severity_counts, 
                        labels=severity_counts.index, 
                        autopct='%1.1f%%',
                        startangle=90, 
                        colors=colors_ordered,
                        textprops={'fontsize': 9, 'color': 'white' if sum(severity_counts) > 10 else 'black'}, # Adjust text color based on size
                        wedgeprops={'edgecolor': '#333', 'linewidth': 0.5} # Add edge color
                    )
                    ax1.axis('equal')
                    st.pyplot(fig1)
                else:
                    st.caption("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á")
            else:
                st.caption("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'predicted_severity'")

        # 3.3 Cases over Time (Line Chart)
        with chart_col2:
            st.markdown("##### üìà ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏Ñ‡∏™‡∏ï‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤")
            if 'timestamp' in df_log.columns:
                 df_log['date'] = df_log['timestamp'].dt.date
                 cases_over_time = df_log.groupby('date').size().rename("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏Ñ‡∏™")
                 if not cases_over_time.empty:
                      st.line_chart(cases_over_time)
                 else:
                      st.caption("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Ñ‡∏™‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å")
            else:
                 st.caption("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ß‡∏•‡∏≤ (timestamp) ‡πÉ‡∏ô Log")
        
        st.markdown("---")

        # 3.4 Risk Factor Analysis (Bar Chart)
        st.markdown("### ‚ùó ‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏™ '‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å'")
        
        risk_cols_in_log = [
            'risk1', 'risk2', 'risk3', 'risk4', 'risk5',
            'head_injury', 'is_night', 'cannabis', 'amphetamine', 'drugs'
        ]
        # Filter only columns that actually exist in the log
        risk_cols_available = [col for col in risk_cols_in_log if col in df_log.columns]

        if "predicted_severity" in df_log.columns:
            fatal_cases = df_log[df_log["predicted_severity"] == "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å"]
            
            if not fatal_cases.empty and risk_cols_available:
                # Ensure risk columns are numeric (convert bools/objects if necessary)
                fatal_cases_numeric = fatal_cases.copy()
                for r_col in risk_cols_available:
                    fatal_cases_numeric[r_col] = pd.to_numeric(fatal_cases_numeric[r_col], errors='coerce').fillna(0)

                # Sum only columns that are binary (0 or 1)
                binary_risk_cols = [col for col in risk_cols_available if fatal_cases_numeric[col].isin([0, 1]).all()]
                
                if binary_risk_cols:
                    risk_counts_fatal = fatal_cases_numeric[binary_risk_cols].sum().sort_values(ascending=False)
                    risk_counts_fatal = risk_counts_fatal[risk_counts_fatal > 0] # Filter out 0 counts

                    risk_display_names = {
                        "risk1": "‡∏î‡∏∑‡πà‡∏°‡πÅ‡∏≠‡∏•‡∏Å‡∏≠‡∏Æ‡∏≠‡∏•‡πå", "risk2": "‡πÉ‡∏ä‡πâ‡∏¢‡∏≤‡πÄ‡∏™‡∏û‡∏ï‡∏¥‡∏î", "risk3": "‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡πÄ‡∏Ç‡πá‡∏°‡∏Ç‡∏±‡∏î",
                        "risk4": "‡πÑ‡∏°‡πà‡∏™‡∏ß‡∏°‡∏´‡∏°‡∏ß‡∏Å", "risk5": "‡πÉ‡∏ä‡πâ‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå",
                        "head_injury": "‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡∏®‡∏µ‡∏£‡∏©‡∏∞", "is_night": "‡πÄ‡∏Å‡∏¥‡∏î‡∏Å‡∏•‡∏≤‡∏á‡∏Ñ‡∏∑‡∏ô",
                        "cannabis": "‡∏Å‡∏±‡∏ç‡∏ä‡∏≤", "amphetamine": "‡∏¢‡∏≤‡∏ö‡πâ‡∏≤", "drugs": "‡∏¢‡∏≤‡∏≠‡∏∑‡πà‡∏ô ‡πÜ"
                    }
                    risk_counts_fatal.index = risk_counts_fatal.index.map(risk_display_names).fillna(risk_counts_fatal.index)

                    if not risk_counts_fatal.empty:
                        fig3, ax3 = plt.subplots(figsize=(7, max(3, len(risk_counts_fatal)*0.4)))
                        sns.barplot(x=risk_counts_fatal.values, y=risk_counts_fatal.index, ax=ax3, palette="viridis")
                        ax3.set_xlabel("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏Ñ‡∏™ '‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å' ‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ô‡∏µ‡πâ")
                        ax3.set_ylabel("‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á")
                        plt.tight_layout()
                        st.pyplot(fig3)
                    else:
                        st.caption("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á (0/1) ‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏™‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å")
                else:
                     st.caption("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤ 0/1 ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Log")
            elif fatal_cases.empty:
                st.caption("‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏Ñ‡∏™ '‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å' ‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ")
            else:
                st.caption("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÉ‡∏ô Log")
        else:
             st.caption("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'predicted_severity' ‡πÉ‡∏ô Log")
             
        # 3.5 Insights & Recommendations
        st.markdown("---")
        st.markdown("### üí° ‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡πÄ‡∏ä‡∏¥‡∏á‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå")
        insights_generated = False
        if fatal_ratio > 10: # Example threshold
             st.warning("üö® ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏Ñ‡∏™ '‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å' ‡∏Ñ‡πà‡∏≠‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡∏™‡∏π‡∏á: ‡∏Ñ‡∏ß‡∏£‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå Triage ‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏±‡∏î‡∏™‡∏£‡∏£‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏´‡πâ‡∏≠‡∏á‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°")
             insights_generated = True
        if 'risk_counts_fatal' in locals() and not risk_counts_fatal.empty:
             top_risk = risk_counts_fatal.index[0]
             st.info(f"üìå ‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏™ '‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å' ‡∏Ñ‡∏∑‡∏≠ '{top_risk}': ‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏£‡∏ì‡∏£‡∏á‡∏Ñ‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏ï‡∏£‡∏Å‡∏≤‡∏£‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ô‡∏µ‡πâ")
             insights_generated = True
        if not insights_generated and total_cases > 5: # Only show if some data exists
             st.info("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Log ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥")

    else: # If df_log is None or empty
        st.info("‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÉ‡∏ô‡πÅ‡∏ó‡πá‡∏ö 'Clinical Risk Prediction' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà")
        if log_load_error:
            st.error(f"‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Log ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {log_load_error}")

st.markdown("---")
st.markdown("Developed by AI for Road Safety | Data Source: Injury Surveillance (IS) - MOPH")
"
I'm not asking for any changes, I'm just updating the file.

