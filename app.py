import os
import json
import joblib
import numpy as np
import pandas as pd
import streamlit as st
from catboost import CatBoostClassifier # Needed even when loading model
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder # Needed for preprocessing

# ----------------------------------------------------------
# ‚öôÔ∏è Page Setup
# ----------------------------------------------------------
st.set_page_config(page_title="Road Accident AI Decision Support", page_icon="üè•", layout="wide")
st.title("üè• Road Accident AI for Clinical Decision Support")
st.caption("‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•")

# --- Define File Paths ---
MODEL_PATH = "predict_catboost_multi.pkl"
ENCODERS_PATH = "encoders_multi.pkl"
FEATURES_PATH = "features_multi.json"
KMEANS_PATH = "kmeans_cluster_model.pkl"
SCALER_PATH = "scaler_cluster.pkl"
RULES_MINOR_PATH = "apriori_rules_minor.pkl"
RULES_SEVERE_PATH = "apriori_rules_severe.pkl"
RULES_FATAL_PATH = "apriori_rules_fatal.pkl"
LOG_FILE = "prediction_log.csv"

# ----------------------------------------------------------
# üì¶ Load Models + Show in Expander (Improved Error Handling)
# ----------------------------------------------------------
@st.cache_resource
def load_all():
    """Loads all necessary model files and returns them."""
    loaded_items = {}
    msgs = []

    files_to_load = {
        "model": (MODEL_PATH, "Clinical Severity Model"),
        "encoders": (ENCODERS_PATH, "Encoders for Clinical Data"),
        "features": (FEATURES_PATH, "Model Features Configuration"),
        "kmeans": (KMEANS_PATH, "KMeans Clustering Model"),
        "scaler": (SCALER_PATH, "Scaler for Clustering"),
        "rules_minor": (RULES_MINOR_PATH, "Apriori Rules (Minor)"),
        "rules_severe": (RULES_SEVERE_PATH, "Apriori Rules (Severe)"),
        "rules_fatal": (RULES_FATAL_PATH, "Apriori Rules (Fatal)"),
    }

    for key, (path, description) in files_to_load.items():
        try:
            if path.endswith(".json"):
                with open(path, "r", encoding="utf-8") as f:
                    loaded_items[key] = json.load(f)
            else: # .pkl files
                loaded_items[key] = joblib.load(path)
            msgs.append(f"‚úÖ {os.path.basename(path)} ‚Äî {description}")
        except FileNotFoundError:
            loaded_items[key] = None # Default for failed load
            if key == 'features': loaded_items[key] = [] # Specific default for features
            if key == 'encoders': loaded_items[key] = {} # Specific default for encoders
            msgs.append(f"‚ùå File not found: {os.path.basename(path)} ‚Äî {description}")
        except Exception as e:
            loaded_items[key] = None # Default for failed load
            if key == 'features': loaded_items[key] = [] # Specific default for features
            if key == 'encoders': loaded_items[key] = {} # Specific default for encoders
            msgs.append(f"‚ö†Ô∏è Error loading {os.path.basename(path)}: {e}")

    # Display loading status
    with st.expander("üìÇ File Loading Status", expanded=False):
        # --- FIXED CHECK: Check for None, empty list/dict appropriately ---
        all_loaded_check = []
        for key, item in loaded_items.items():
            if key == 'features':
                all_loaded_check.append(isinstance(item, list) and len(item) > 0)
            elif key == 'encoders':
                 # Encoders can be an empty dict if no categorical features were encoded originally
                 all_loaded_check.append(isinstance(item, dict)) # Check if it's a dict (even empty)
            else:
                all_loaded_check.append(item is not None)

        all_loaded = all(all_loaded_check)
        # --- END OF FIX ---

        if all_loaded:
            st.success("All required files loaded successfully.")
        else:
            st.warning("Some files could not be loaded or are empty. Please check file paths and availability.")

        for m in msgs:
            if "‚úÖ" in m:
                st.caption(m)
            else:
                st.caption(f":warning: {m}") # Highlight errors/warnings

    return (
        loaded_items.get("model"),
        loaded_items.get("encoders"),
        loaded_items.get("features"),
        loaded_items.get("kmeans"),
        loaded_items.get("scaler"),
        loaded_items.get("rules_minor"),
        loaded_items.get("rules_severe"),
        loaded_items.get("rules_fatal"),
    )

# ----------------------------------------------------------
# ‚úÖ Load resources using the function
# ----------------------------------------------------------
model, encoders, features, kmeans, scaler, rules_minor, rules_severe, rules_fatal = load_all()

# --- Check if essential components loaded ---
# Updated check for encoders (can be empty dict {})
essentials_loaded = model and features and encoders is not None

# ----------------------------------------------------------
# üß© Manual Mappings & Helper Functions
# ----------------------------------------------------------
activity_mapping = {
    "0": "‡πÄ‡∏î‡∏¥‡∏ô‡πÄ‡∏ó‡πâ‡∏≤", "1": "‡πÇ‡∏î‡∏¢‡∏™‡∏≤‡∏£‡∏û‡∏≤‡∏´‡∏ô‡∏∞‡∏™‡∏≤‡∏ò‡∏≤‡∏£‡∏ì‡∏∞", "2": "‡πÇ‡∏î‡∏¢‡∏™‡∏≤‡∏£‡∏û‡∏≤‡∏´‡∏ô‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•",
    "3": "‡∏Ç‡∏±‡∏ö‡∏Ç‡∏µ‡πà‡∏û‡∏≤‡∏´‡∏ô‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•", "4": "‡∏ó‡∏≥‡∏á‡∏≤‡∏ô", "5": "‡πÄ‡∏•‡πà‡∏ô‡∏Å‡∏µ‡∏¨‡∏≤", "6": "‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏≠‡∏∑‡πà‡∏ô ‡πÜ", "Unknown": "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏"
}
aplace_mapping = {
    "10": "‡∏ö‡πâ‡∏≤‡∏ô‡∏û‡∏±‡∏Å‡∏≠‡∏≤‡∏®‡∏±‡∏¢", "11": "‡∏ñ‡∏ô‡∏ô/‡∏ó‡∏≤‡∏á‡∏´‡∏•‡∏ß‡∏á", "12": "‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô",
    "13": "‡πÇ‡∏£‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô/‡∏™‡∏ñ‡∏≤‡∏ö‡∏±‡∏ô‡∏®‡∏∂‡∏Å‡∏©‡∏≤", "14": "‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏ò‡∏≤‡∏£‡∏ì‡∏∞", "15": "‡∏≠‡∏∑‡πà‡∏ô ‡πÜ", "Unknown": "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏"
}
prov_mapping = {
    "10": "‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£", "20": "‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà", "30": "‡∏Ç‡∏≠‡∏ô‡πÅ‡∏Å‡πà‡∏ô", "40": "‡∏†‡∏π‡πÄ‡∏Å‡πá‡∏ï",
    "50": "‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤", "60": "‡∏™‡∏á‡∏Ç‡∏•‡∏≤", "99": "‡∏≠‡∏∑‡πà‡∏ô ‡πÜ", "Unknown": "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏"
}
# Add default mapping for unknown values generated during preprocessing fillna('Unknown')
activity_mapping.setdefault("Unknown", "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏")
aplace_mapping.setdefault("Unknown", "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏")
prov_mapping.setdefault("Unknown", "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏")

severity_map = {0: "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ô‡πâ‡∏≠‡∏¢", 1: "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á", 2: "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å"}
advice_map = {
    "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ô‡πâ‡∏≠‡∏¢": "‡∏î‡∏π‡πÅ‡∏•‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡πÄ‡∏ù‡πâ‡∏≤‡∏£‡∏∞‡∏ß‡∏±‡∏á‡∏ã‡πâ‡∏≥‡∏ó‡∏∏‡∏Å 15‚Äì30 ‡∏ô‡∏≤‡∏ó‡∏µ",
    "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á": "‡∏™‡πà‡∏á‡∏ï‡∏£‡∏ß‡∏à‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏£‡∏ô‡πâ‡∏≥ / ‡∏¢‡∏≤‡πÅ‡∏Å‡πâ‡∏õ‡∏ß‡∏î / ‡πÄ‡∏ù‡πâ‡∏≤‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏ä‡∏µ‡∏û‡πÉ‡∏Å‡∏•‡πâ‡∏ä‡∏¥‡∏î",
    "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å": "‡πÅ‡∏à‡πâ‡∏á‡∏ó‡∏µ‡∏°‡∏™‡∏´‡∏™‡∏≤‡∏Ç‡∏≤ ‡πÄ‡∏õ‡∏¥‡∏î‡∏ó‡∏≤‡∏á‡πÄ‡∏î‡∏¥‡∏ô‡∏´‡∏≤‡∏¢‡πÉ‡∏à ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏´‡πâ‡∏≠‡∏á‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏™‡πà‡∏á‡∏ï‡πà‡∏≠‡∏î‡πà‡∏ß‡∏ô"
}
triage_color = {"‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ô‡πâ‡∏≠‡∏¢": "#4CAF50", "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á": "#FFC107", "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å": "#F44336"}

# --- Preprocessing Function (Modified to use loaded features/encoders) ---
#@st.cache_data # Cache this function if inputs are likely to repeat
def preprocess_input(data_dict, loaded_encoders, expected_features):
    """Preprocesses user input dictionary based on loaded encoders and features."""
    if not expected_features:
        st.error("Feature list is empty. Cannot preprocess.")
        return None
    if loaded_encoders is None:
         st.warning("Encoders not loaded. Categorical features might not be processed correctly.")
         loaded_encoders = {} # Use an empty dict to avoid errors


    df = pd.DataFrame([data_dict])

    # Map display values back to codes before encoding
    reverse_activity = {v: k for k, v in activity_mapping.items()}
    reverse_aplace = {v: k for k, v in aplace_mapping.items()}
    reverse_prov = {v: k for k, v in prov_mapping.items()}

    # Use .get() with a default 'Unknown' code if the display value isn't found
    df['activity'] = df['activity'].apply(lambda x: reverse_activity.get(x, "Unknown"))
    df['aplace'] = df['aplace'].apply(lambda x: reverse_aplace.get(x, "Unknown"))
    df['prov'] = df['prov'].apply(lambda x: reverse_prov.get(x, "Unknown"))

    # Reindex first to ensure all expected columns are present
    df = df.reindex(columns=expected_features, fill_value=0) # Use 0 as default fill

    # Clean potential string issues and fill NaNs *after* reindexing
    # Important: Ensure 'Unknown' is handled consistently with how missing/cleaned values were treated before encoding
    clean_values = ["None", "N/A", "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏", "N", "nan", "NaN", "", " "]
    df = df.replace(clean_values, "Unknown") # Replace various missing representations with 'Unknown'
    df = df.fillna("Unknown") # Fill any actual NaNs with 'Unknown' string for categorical, 0 for potential numerics later


    # Encode categorical features using loaded encoders
    for col, le in loaded_encoders.items():
        if col in df.columns:
            df[col] = df[col].astype(str) # Ensure string type before transform
            # Handle unseen labels by mapping them to the 'Unknown' class index if it exists, otherwise default to 0
            unknown_class_index = 0 # Default index if 'Unknown' not in classes
            if "Unknown" in le.classes_:
                try:
                  unknown_class_index = le.transform(["Unknown"])[0]
                except ValueError:
                  pass # Should not happen if 'Unknown' is in classes_ but handle defensively

            df[col] = df[col].apply(lambda x: le.transform([x])[0] if x in le.classes_ else unknown_class_index)


    # --- Create Engineered Features (must match training - check feature list) ---
    # Ensure necessary base columns exist before creating engineered ones
    if 'age' in df.columns:
        df['age'] = pd.to_numeric(df['age'], errors='coerce').fillna(0) # Convert age, fill errors with 0
        if "age_group_60plus" in expected_features:
             df["age_group_60plus"] = (df["age"] >= 60).astype(int)

    risk_cols_in_features = [f"risk{i}" for i in range(1, 6) if f"risk{i}" in expected_features]
    if "risk_count" in expected_features:
        # Convert risk columns to numeric before summing, coercing errors to 0
        for r_col in risk_cols_in_features:
            if r_col in df.columns:
                 df[r_col] = pd.to_numeric(df[r_col], errors='coerce').fillna(0)
            else:
                 df[r_col] = 0 # Ensure column exists if expected but missing in input_dict

        if risk_cols_in_features: # Only sum if relevant risk columns exist
             df["risk_count"] = df[risk_cols_in_features].sum(axis=1)
        else:
             df["risk_count"] = 0 # If risk_count expected but base risks aren't features


    if 'is_night' in df.columns:
        df['is_night'] = pd.to_numeric(df['is_night'], errors='coerce').fillna(0) # Convert, fill errors with 0
        if "night_flag" in expected_features:
            df["night_flag"] = df["is_night"].astype(int)
    elif "night_flag" in expected_features: # If night_flag expected but is_night isn't
         df["night_flag"] = 0


    # Ensure all columns are numeric at the end and fill any remaining NaNs (e.g., from failed numeric conversions)
    for col in df.columns:
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)


    # Final check: Ensure column order matches exactly and return
    try:
        df = df[expected_features]
    except KeyError as e:
        missing_keys = set(expected_features) - set(df.columns)
        st.error(f"Mismatch in expected features during final step. Missing: {missing_keys}. Error: {e}")
        return None
    except Exception as e:
        st.error(f"An unexpected error occurred ensuring final feature order: {e}")
        return None


    return df


# --- Function to decode Apriori rules ---
#@st.cache_data # Cache decoding if rules don't change often
def decode_set(item_set):
    """Converts a frozenset of coded items to readable strings."""
    if not isinstance(item_set, (frozenset, set)):
        return str(item_set)

    # Define mappings (expand as needed based on your Apriori basket items from notebook)
    replacements = {
        "Male": "‡πÄ‡∏û‡∏®‡∏ä‡∏≤‡∏¢", "Female": "‡πÄ‡∏û‡∏®‡∏´‡∏ç‡∏¥‡∏á", "Age_60+": "‡∏≠‡∏≤‡∏¢‡∏∏ 60+",
        "Nighttime": "‡∏Å‡∏•‡∏≤‡∏á‡∏Ñ‡∏∑‡∏ô", "Head_Injury": "‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡∏®‡∏µ‡∏£‡∏©‡∏∞",
        "Risk_Alcohol": "‡∏î‡∏∑‡πà‡∏°‡πÅ‡∏≠‡∏•‡∏Å‡∏≠‡∏Æ‡∏≠‡∏•‡πå", "Risk_Drugs_General": "‡πÉ‡∏ä‡πâ‡∏¢‡∏≤‡πÄ‡∏™‡∏û‡∏ï‡∏¥‡∏î(‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ)",
        "Risk_No_Belt": "‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡πÄ‡∏Ç‡πá‡∏°‡∏Ç‡∏±‡∏î", "Risk_No_Helmet": "‡πÑ‡∏°‡πà‡∏™‡∏ß‡∏°‡∏´‡∏°‡∏ß‡∏Å",
        "Risk_Phone_Use": "‡πÉ‡∏ä‡πâ‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå‡∏Ç‡∏ì‡∏∞‡∏Ç‡∏±‡∏ö",
        "Drug_Kratom": "‡∏Å‡∏£‡∏∞‡∏ó‡πà‡∏≠‡∏°", "Drug_Cannabis": "‡∏Å‡∏±‡∏ç‡∏ä‡∏≤", "Drug_Amphetamine": "‡∏¢‡∏≤‡∏ö‡πâ‡∏≤",
        "Severity_Minor": "‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢", "Severity_Severe": "‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á",
        "Severity_Fatal": "‡πÄ‡∏™‡∏µ‡∏¢‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï"
        # Add more mappings corresponding to df_basket column names in the notebook
    }
    # Sort for consistency before joining
    readable = [replacements.get(str(item), str(item)) for item in sorted(list(item_set))]
    return ", ".join(readable)


# ==========================================================
# ü©∫ TAB SYSTEM
# ==========================================================
tab1, tab2, tab3, tab4 = st.tabs([
    "üß† Clinical Risk Prediction",
    "üë• Cluster Insight",
    "üß© Risk Association",
    "üìä Clinical Summary Dashboard"
])

# Initialize session state for submit button if it doesn't exist
if 'submit_pressed' not in st.session_state:
    st.session_state.submit_pressed = False
if 'prediction_label' not in st.session_state:
    st.session_state.prediction_label = "‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô"
if 'processed_input_for_tabs' not in st.session_state:
    st.session_state.processed_input_for_tabs = None
if 'raw_input_for_tabs' not in st.session_state:
    st.session_state.raw_input_for_tabs = {}


# ----------------------------------------------------------
# üß† TAB 1 ‚Äî CatBoost Prediction
# ----------------------------------------------------------
with tab1:
    st.subheader("üß† Clinical Severity Prediction")
    st.caption("‡∏£‡∏∞‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå")

    if not essentials_loaded:
        st.error("Cannot proceed with prediction. Essential model files (model, features, encoders) are missing or empty.")
    else:
        st.subheader("üìã ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö")
        with st.form("input_form"):
            # --- Input fields ---
            age = st.number_input("‡∏≠‡∏≤‡∏¢‡∏∏ (‡∏õ‡∏µ)", min_value=0, max_value=120, value=35, key="tab1_age")
            sex = st.radio("‡πÄ‡∏û‡∏®", ["‡∏´‡∏ç‡∏¥‡∏á", "‡∏ä‡∏≤‡∏¢"], horizontal=True, key="tab1_sex") # Display text
            is_night = st.checkbox("‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏•‡∏≤‡∏á‡∏Ñ‡∏∑‡∏ô (18:00-06:00)", value=False, key="tab1_is_night")
            head_injury = st.checkbox("‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡∏ó‡∏µ‡πà‡∏®‡∏µ‡∏£‡∏©‡∏∞", value=False, key="tab1_head_injury")
            mass_casualty = st.checkbox("‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ú‡∏π‡πâ‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å", value=False, key="tab1_mass_casualty")

            st.markdown("**‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á (Risk Factors - ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏≤‡∏Å‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á)**")
            c1, c2, c3, c4, c5 = st.columns(5)
            # Use keys consistent with training data if possible, map later if needed
            with c1: risk1 = st.checkbox("‡∏î‡∏∑‡πà‡∏°‡πÅ‡∏≠‡∏•‡∏Å‡∏≠‡∏Æ‡∏≠‡∏•‡πå (risk1)", key="tab1_risk1") # Matches notebook variable name
            with c2: risk2 = st.checkbox("‡πÉ‡∏ä‡πâ‡∏¢‡∏≤‡πÄ‡∏™‡∏û‡∏ï‡∏¥‡∏î(‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ) (risk2)", key="tab1_risk2") # Matches notebook variable name
            with c3: risk3 = st.checkbox("‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡πÄ‡∏Ç‡πá‡∏°‡∏Ç‡∏±‡∏î (risk3)", key="tab1_risk3") # Matches notebook variable name
            with c4: risk4 = st.checkbox("‡πÑ‡∏°‡πà‡∏™‡∏ß‡∏°‡∏´‡∏°‡∏ß‡∏Å‡∏ô‡∏¥‡∏£‡∏†‡∏±‡∏¢ (risk4)", key="tab1_risk4") # Matches notebook variable name
            with c5: risk5 = st.checkbox("‡πÉ‡∏ä‡πâ‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå‡∏Ç‡∏ì‡∏∞‡∏Ç‡∏±‡∏ö (risk5)", key="tab1_risk5") # Matches notebook variable name


            st.markdown("**‡∏™‡∏≤‡∏£‡πÄ‡∏™‡∏û‡∏ï‡∏¥‡∏î/‡∏¢‡∏≤‡πÉ‡∏ô‡∏£‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏¢ (‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏≤‡∏Å‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á)**")
            d1, d2, d3 = st.columns(3)
            with d1: cannabis = st.checkbox("‡∏Å‡∏±‡∏ç‡∏ä‡∏≤", key="tab1_cannabis")
            with d2: amphetamine = st.checkbox("‡∏¢‡∏≤‡∏ö‡πâ‡∏≤ / ‡πÅ‡∏≠‡∏°‡πÄ‡∏ü‡∏ï‡∏≤‡∏°‡∏µ‡∏ô", key="tab1_amphetamine")
            with d3: drugs = st.checkbox("‡∏¢‡∏≤‡∏≠‡∏∑‡πà‡∏ô ‡πÜ (drugs)", key="tab1_drugs") # 'drugs' from notebook


            st.markdown("**‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Ç‡∏≠‡∏á‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå**")
            # Get display values from selectbox
            activity_display = st.selectbox("‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏Ç‡∏ì‡∏∞‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏", list(activity_mapping.values()), key="tab1_activity_display", index=list(activity_mapping.values()).index("‡∏Ç‡∏±‡∏ö‡∏Ç‡∏µ‡πà‡∏û‡∏≤‡∏´‡∏ô‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•")) # Default example
            aplace_display = st.selectbox("‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏", list(aplace_mapping.values()), key="tab1_aplace_display", index=list(aplace_mapping.values()).index("‡∏ñ‡∏ô‡∏ô/‡∏ó‡∏≤‡∏á‡∏´‡∏•‡∏ß‡∏á")) # Default example
            prov_display = st.selectbox("‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏", list(prov_mapping.values()), key="tab1_prov_display", index=list(prov_mapping.values()).index("‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£")) # Default example


            submit_button_tab1 = st.form_submit_button("üîé ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á")

        if submit_button_tab1:
            st.session_state.submit_pressed = True # Mark that form was submitted

            # --- Prepare input dictionary using display values for categorical ---
            input_data = {
                "age": age,
                "sex": '1' if sex == "‡∏ä‡∏≤‡∏¢" else '2', # Map back to '1'/'2' code used in notebook
                "is_night": int(is_night),
                "head_injury": int(head_injury),
                "mass_casualty": int(mass_casualty),
                "risk1": int(risk1),
                "risk2": int(risk2),
                "risk3": int(risk3),
                "risk4": int(risk4),
                "risk5": int(risk5),
                "cannabis": int(cannabis),
                "amphetamine": int(amphetamine),
                "drugs": int(drugs),
                "activity": activity_display, # Pass display value to preprocess
                "aplace": aplace_display,      # Pass display value to preprocess
                "prov": prov_display          # Pass display value to preprocess
            }
             # Store raw input for other tabs (using display values)
            st.session_state.raw_input_for_tabs = {
                "age": age, "sex": sex, "is_night": is_night, "head_injury": head_injury,
                "mass_casualty": mass_casualty, "risk1": risk1, "risk2": risk2,
                "risk3": risk3, "risk4": risk4, "risk5": risk5, "cannabis": cannabis,
                "amphetamine": amphetamine, "drugs": drugs, "activity": activity_display,
                "aplace": aplace_display, "prov": prov_display
            }


            # --- Preprocess and Predict ---
            # Make sure 'features' list is loaded correctly
            if not features:
                 st.error("Feature list could not be loaded. Cannot preprocess input.")
            else:
                X_input = preprocess_input(input_data, encoders, features)
                st.session_state.processed_input_for_tabs = X_input # Store processed input for other tabs


                if X_input is not None:
                    try:
                        probs = model.predict_proba(X_input)[0]
                        pred_class = int(np.argmax(probs))
                        st.session_state.prediction_label = severity_map.get(pred_class, "‡πÑ‡∏°‡πà‡∏ó‡∏£‡∏≤‡∏ö") # Store label
                        color = triage_color.get(st.session_state.prediction_label, "#2196F3") # Default blue

                        # Display Triage Color Box
                        st.markdown(
                            f"<div style='background-color:{color};padding:12px;border-radius:10px;margin-top: 15px;'>"
                            f"<h3 style='color:white;text-align:center;'>‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ì‡πå: {st.session_state.prediction_label}</h3></div>",
                            unsafe_allow_html=True
                        )
                        # Display Advice and Confidence
                        st.info(f"üí° ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô: {advice_map.get(st.session_state.prediction_label, 'N/A')}")
                        st.caption(f"üß† ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö: {probs[pred_class]*100:.1f}%")

                        # --- Save prediction log ---
                        try:
                            log_entry = {
                                "timestamp": pd.Timestamp.now(tz='Asia/Bangkok').strftime('%Y-%m-%d %H:%M:%S %Z'), # Format timestamp
                                "age": age,
                                "sex": sex, # Log display value '‡∏ä‡∏≤‡∏¢'/'‡∏´‡∏ç‡∏¥‡∏á'
                                "predicted_severity": st.session_state.prediction_label,
                                "prov": prov_display, # Log display value
                                "is_night": int(is_night),
                                "risk1": int(risk1),
                                "risk2": int(risk2),
                                "risk3": int(risk3),
                                "risk4": int(risk4),
                                "risk5": int(risk5),
                                "head_injury": int(head_injury) # Add head injury to log
                            }
                            new_row = pd.DataFrame([log_entry])

                            # Ensure header exists or write it
                            write_header = not os.path.exists(LOG_FILE)
                            new_row.to_csv(LOG_FILE, mode="a", index=False, header=write_header, encoding='utf-8-sig')

                            st.success("üìÅ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö Dashboard ‡πÅ‡∏•‡πâ‡∏ß")
                        except Exception as log_e:
                            st.warning(f"Could not save prediction log: {log_e}")

                    except AttributeError as ae:
                         st.error(f"Prediction error: Model object might not be loaded correctly or is not a CatBoostClassifier. Details: {ae}")
                    except Exception as pred_e:
                        st.error(f"An error occurred during prediction: {pred_e}")
                        st.error("Please check the input data and model files.")
                        # st.dataframe(X_input) # Optional: show processed data for debugging
                else:
                    st.error("Input preprocessing failed. Cannot make prediction.")


# ----------------------------------------------------------
# üë• TAB 2 ‚Äî K-Means Cluster Analysis
# ----------------------------------------------------------
with tab2:
    st.subheader("üë• Patient Segmentation (K-Means)")
    st.caption("‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ú‡∏π‡πâ‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏™‡∏£‡∏£‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÄ‡∏ä‡∏¥‡∏á‡∏£‡∏∏‡∏Å")

    # Check if form was submitted in Tab 1
    if not st.session_state.get('submit_pressed', False): # Use .get() for safety
        st.info("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏Å‡∏î '‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á' ‡πÉ‡∏ô‡πÅ‡∏ó‡πá‡∏ö‡πÅ‡∏£‡∏Å‡∏Å‡πà‡∏≠‡∏ô")
    elif kmeans is None or scaler is None:
        st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏• K-Means ‡∏´‡∏£‡∏∑‡∏≠ Scaler ‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ß‡πâ")
    elif st.session_state.get('processed_input_for_tabs') is None:
         st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Input ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Clustering ‡πÑ‡∏î‡πâ")
    else:
        # --- Display Patient Summary ---
        st.markdown("### üßæ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö")
        raw_input = st.session_state.get('raw_input_for_tabs', {}) # Use .get()
        summary_cols = st.columns(3)
        summary_cols[0].metric("‡∏≠‡∏≤‡∏¢‡∏∏", f"{raw_input.get('age', 'N/A')} ‡∏õ‡∏µ")
        summary_cols[1].metric("‡πÄ‡∏û‡∏®", raw_input.get('sex', 'N/A')) # Use stored display value
        summary_cols[2].metric("‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á", st.session_state.get('prediction_label', 'N/A')) # Use .get()

        # Generate risk summary from stored raw boolean values
        risk_summary = []
        if raw_input.get('risk1'): risk_summary.append("‡∏î‡∏∑‡πà‡∏°‡πÅ‡∏≠‡∏•‡∏Å‡∏≠‡∏Æ‡∏≠‡∏•‡πå")
        if raw_input.get('risk2'): risk_summary.append("‡πÉ‡∏ä‡πâ‡∏¢‡∏≤‡πÄ‡∏™‡∏û‡∏ï‡∏¥‡∏î(‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ)")
        if raw_input.get('risk3'): risk_summary.append("‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡πÄ‡∏Ç‡πá‡∏°‡∏Ç‡∏±‡∏î")
        if raw_input.get('risk4'): risk_summary.append("‡πÑ‡∏°‡πà‡∏™‡∏ß‡∏°‡∏´‡∏°‡∏ß‡∏Å‡∏ô‡∏¥‡∏£‡∏†‡∏±‡∏¢")
        if raw_input.get('risk5'): risk_summary.append("‡πÉ‡∏ä‡πâ‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå‡∏Ç‡∏ì‡∏∞‡∏Ç‡∏±‡∏ö")
        if raw_input.get('head_injury'): risk_summary.append("‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡∏®‡∏µ‡∏£‡∏©‡∏∞")
        if raw_input.get('cannabis'): risk_summary.append("‡∏Å‡∏±‡∏ç‡∏ä‡∏≤")
        if raw_input.get('amphetamine'): risk_summary.append("‡∏¢‡∏≤‡∏ö‡πâ‡∏≤")
        if raw_input.get('drugs'): risk_summary.append("‡∏¢‡∏≤‡∏≠‡∏∑‡πà‡∏ô ‡πÜ")
        if raw_input.get('is_night'): risk_summary.append("‡πÄ‡∏Å‡∏¥‡∏î‡∏Å‡∏•‡∏≤‡∏á‡∏Ñ‡∏∑‡∏ô")

        st.markdown(f"**‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÄ‡∏î‡πà‡∏ô:** {', '.join(risk_summary) if risk_summary else '-'}")
        st.markdown("---")

        # --- Perform Clustering ---
        try:
            # Prepare data specifically for clustering - using the *processed* input
            X_input_processed = st.session_state.processed_input_for_tabs

            # Identify features used by the scaler during training
            if hasattr(scaler, "feature_names_in_"):
                cluster_features_used = scaler.feature_names_in_
            else:
                 # Fallback: try to infer from scaler attributes if possible, else error
                 if hasattr(scaler, 'n_features_in_'):
                      if scaler.n_features_in_ == X_input_processed.shape[1]:
                           cluster_features_used = X_input_processed.columns.tolist() # Assume same features/order
                           st.warning("Scaler object lacks explicit feature names. Assuming features match processed input order.")
                      else:
                           st.error(f"Scaler expects {scaler.n_features_in_} features, but processed input has {X_input_processed.shape[1]}. Cannot proceed with clustering.")
                           cluster_features_used = None
                 else:
                    st.error("Cannot determine features expected by the scaler. Clustering aborted.")
                    cluster_features_used = None


            if cluster_features_used:
                # Ensure the processed input DataFrame has exactly these columns in the correct order
                X_cluster_input = X_input_processed.copy()
                missing_cols = set(cluster_features_used) - set(X_cluster_input.columns)
                if missing_cols:
                    st.warning(f"Processed input is missing columns expected by scaler: {missing_cols}. Filling with 0.")
                    for col in missing_cols:
                        X_cluster_input[col] = 0

                # Select and reorder columns
                try:
                    X_cluster_input = X_cluster_input[cluster_features_used]
                except KeyError as e:
                     st.error(f"Error selecting/ordering columns for scaler: {e}")
                     X_cluster_input = None # Prevent further processing


                if X_cluster_input is not None and not X_cluster_input.empty:
                    X_scaled = scaler.transform(X_cluster_input)
                    cluster_label = int(kmeans.predict(X_scaled)[0])

                    # Example Cluster Descriptions (Adjust based on your actual cluster analysis from notebook)
                    cluster_desc = {
                        0: "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ/‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ï‡πà‡∏≥: ‡∏°‡∏±‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏®‡∏ä‡∏≤‡∏¢ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡∏®‡∏µ‡∏£‡∏©‡∏∞‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏î‡πà‡∏ô‡∏ä‡∏±‡∏î (Cluster 0 Profile)",
                        1: "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á/‡∏´‡∏ç‡∏¥‡∏á: ‡∏°‡∏±‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏®‡∏´‡∏ç‡∏¥‡∏á ‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡∏®‡∏µ‡∏£‡∏©‡∏∞ (Cluster 1 Profile)",
                        2: "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á/‡∏¢‡∏≤‡πÄ‡∏™‡∏û‡∏ï‡∏¥‡∏î: ‡∏û‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏¢‡∏≤‡πÄ‡∏™‡∏û‡∏ï‡∏¥‡∏î (risk2=1) ‡∏™‡∏π‡∏á ‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡∏®‡∏µ‡∏£‡∏©‡∏∞‡∏£‡πà‡∏ß‡∏° (Cluster 2 Profile)"
                        # Add descriptions reflecting the means from your notebook analysis
                    }

                    st.markdown(f"### üìä ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°: **Cluster {cluster_label}**")
                    st.info(f"**‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Å‡∏•‡∏∏‡πà‡∏° (‡πÇ‡∏î‡∏¢‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì):** {cluster_desc.get(cluster_label, '‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ô‡∏µ‡πâ')}")
                    st.caption("üí° ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô ‡πÅ‡∏•‡∏∞‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏Ñ‡∏°‡πÄ‡∏õ‡∏ç‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢")

                else:
                    st.error("Could not prepare valid input for clustering after feature selection.")
            # else: Error already shown about scaler features

        except AttributeError as ae:
             st.error(f"Clustering error: Model object (kmeans or scaler) might not be loaded correctly. Details: {ae}")

        except Exception as e:
            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏° K-Means: {e}")
            # st.dataframe(X_input_processed) # Optional debugging


# ----------------------------------------------------------
# üß© TAB 3 ‚Äî Apriori Risk Association
# ----------------------------------------------------------
with tab3:
    st.subheader("üß© Risk Association Analysis (Apriori)")
    st.caption("‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡πÄ‡∏ä‡∏¥‡∏á‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢")

    # Check if form was submitted in Tab 1
    if not st.session_state.get('submit_pressed', False):
        st.info("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏Å‡∏î '‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á' ‡πÉ‡∏ô‡πÅ‡∏ó‡πá‡∏ö‡πÅ‡∏£‡∏Å‡∏Å‡πà‡∏≠‡∏ô")
    elif rules_minor is None and rules_severe is None and rules_fatal is None:
        st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Å‡∏é Apriori ‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ß‡πâ ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤")
    else:
        # --- Display Patient Summary ---
        st.markdown("### üßæ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö")
        raw_input = st.session_state.get('raw_input_for_tabs', {})
        summary_cols = st.columns(3)
        summary_cols[0].metric("‡∏≠‡∏≤‡∏¢‡∏∏", f"{raw_input.get('age', 'N/A')} ‡∏õ‡∏µ")
        summary_cols[1].metric("‡πÄ‡∏û‡∏®", raw_input.get('sex', 'N/A'))
        summary_cols[2].metric("‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á", st.session_state.get('prediction_label', 'N/A'))

        risk_tags = []
        if raw_input.get('risk1'): risk_tags.append("‡∏î‡∏∑‡πà‡∏°‡πÅ‡∏≠‡∏•‡∏Å‡∏≠‡∏Æ‡∏≠‡∏•‡πå")
        if raw_input.get('risk2'): risk_tags.append("‡πÉ‡∏ä‡πâ‡∏¢‡∏≤‡πÄ‡∏™‡∏û‡∏ï‡∏¥‡∏î(‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ)")
        if raw_input.get('risk3'): risk_tags.append("‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡πÄ‡∏Ç‡πá‡∏°‡∏Ç‡∏±‡∏î")
        if raw_input.get('risk4'): risk_tags.append("‡πÑ‡∏°‡πà‡∏™‡∏ß‡∏°‡∏´‡∏°‡∏ß‡∏Å‡∏ô‡∏¥‡∏£‡∏†‡∏±‡∏¢")
        if raw_input.get('risk5'): risk_tags.append("‡πÉ‡∏ä‡πâ‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå‡∏Ç‡∏ì‡∏∞‡∏Ç‡∏±‡∏ö")
        if raw_input.get('head_injury'): risk_tags.append("‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡∏®‡∏µ‡∏£‡∏©‡∏∞")
        if raw_input.get('cannabis'): risk_tags.append("‡∏Å‡∏±‡∏ç‡∏ä‡∏≤")
        if raw_input.get('amphetamine'): risk_tags.append("‡∏¢‡∏≤‡∏ö‡πâ‡∏≤")
        if raw_input.get('drugs'): risk_tags.append("‡∏¢‡∏≤‡∏≠‡∏∑‡πà‡∏ô ‡πÜ")
        if raw_input.get('is_night'): risk_tags.append("‡πÄ‡∏Å‡∏¥‡∏î‡∏Å‡∏•‡∏≤‡∏á‡∏Ñ‡∏∑‡∏ô")

        st.markdown(f"**‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÄ‡∏î‡πà‡∏ô:** {', '.join(risk_tags) if risk_tags else '-'}")
        st.markdown("---")

        # --- Select and Display Relevant Rules ---
        st.markdown("### üîó ‡∏Å‡∏é‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á (Top 5 by Lift)")

        target_label = st.session_state.get('prediction_label', 'N/A')
        rules_df_to_show = None
        rules_title = f"‡∏Å‡∏é‡∏ó‡∏µ‡πà‡∏ô‡∏≥‡πÑ‡∏õ‡∏™‡∏π‡πà: {target_label}"

        # Check if the loaded rules object is a non-empty DataFrame
        is_valid_df = lambda df: isinstance(df, pd.DataFrame) and not df.empty

        if target_label == "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ô‡πâ‡∏≠‡∏¢" and is_valid_df(rules_minor):
            rules_df_to_show = rules_minor
        elif target_label == "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á" and is_valid_df(rules_severe):
            rules_df_to_show = rules_severe
        elif target_label == "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å" and is_valid_df(rules_fatal):
            rules_df_to_show = rules_fatal

        if rules_df_to_show is not None:
            st.markdown(f"**{rules_title}**")
            # Decode antecedents and consequents for display
            display_df = rules_df_to_show.head(5).copy() # Work with a copy

            # Check if columns exist before applying decode_set
            if 'antecedents' in display_df.columns:
                 display_df["‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ô‡∏≥ (Antecedents)"] = display_df["antecedents"].apply(decode_set)
            else:
                 display_df["‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ô‡∏≥ (Antecedents)"] = "N/A"

            if 'consequents' in display_df.columns:
                 display_df["‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (Consequents)"] = display_df["consequents"].apply(decode_set)
            else:
                 display_df["‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (Consequents)"] = "N/A"


            # Select and rename columns for clarity, handle missing columns gracefully
            cols_to_display = ["‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ô‡∏≥ (Antecedents)", "‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (Consequents)"]
            rename_map = {"support": "Support", "confidence": "Confidence", "lift": "Lift"}
            for col, new_name in rename_map.items():
                if col in display_df.columns:
                    cols_to_display.append(new_name)
                    display_df = display_df.rename(columns={col: new_name})

            # Check if essential columns exist before displaying
            if "‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ô‡∏≥ (Antecedents)" in display_df.columns and "‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (Consequents)" in display_df.columns:
                st.dataframe(
                    display_df[cols_to_display],
                    use_container_width=True,
                    hide_index=True
                )

                # Display interpretation guide
                st.markdown("üìò **‡∏Å‡∏≤‡∏£‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°:**")
                st.markdown("- **Support:** ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ñ‡∏™‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ô‡∏≥‡πÅ‡∏•‡∏∞‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ô‡∏µ‡πâ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô")
                st.markdown("- **Confidence:** ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏Å‡∏¥‡∏î '‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå' ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏û‡∏ö '‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ô‡∏≥' ‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ")
                st.markdown("- **Lift > 1:** ‡∏ö‡πà‡∏á‡∏ä‡∏µ‡πâ‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏ô‡∏±‡∏¢‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ö‡∏±‡∏á‡πÄ‡∏≠‡∏¥‡∏ç) ‡∏¢‡∏¥‡πà‡∏á‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á‡∏¢‡∏¥‡πà‡∏á‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏Å‡∏±‡∏ô‡∏°‡∏≤‡∏Å")
            else:
                 st.error("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏é Apriori ‡πÑ‡∏î‡πâ ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô (antecedents/consequents) ‡∏´‡∏≤‡∏¢‡πÑ‡∏õ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå .pkl")

        else:
            st.info(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Å‡∏é Apriori ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á '{target_label}' ‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏Å‡∏é‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤")


# ----------------------------------------------------------
# üìä TAB 4 ‚Äî Clinical Summary Dashboard
# ----------------------------------------------------------
with tab4:
    st.subheader("üìä Clinical Summary & Insights Dashboard")
    st.caption("‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏ú‡∏π‡πâ‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏ö AI ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡πÄ‡∏ä‡∏¥‡∏á‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå‡πÅ‡∏•‡∏∞‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•")

    # --- Load Log File ---
    df_log = None
    log_load_error = None
    if os.path.exists(LOG_FILE):
        try:
            df_log = pd.read_csv(LOG_FILE, parse_dates=['timestamp'], encoding='utf-8-sig') # Specify encoding
            # Attempt to convert timestamp, handle potential errors
            df_log['timestamp'] = pd.to_datetime(df_log['timestamp'], errors='coerce').dt.tz_localize(None) # Remove timezone for consistency
            df_log = df_log.dropna(subset=['timestamp']) # Drop rows where timestamp conversion failed

            if not df_log.empty:
                 st.success(f"üìÅ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Log ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(df_log):,} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
            else:
                 st.info("‡πÑ‡∏ü‡∏•‡πå Log ‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤ ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
                 df_log = None # Treat empty/invalid log as if it doesn't exist
        except Exception as e:
            log_load_error = f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Log ({LOG_FILE}): {e}"
            st.error(log_load_error)
            df_log = None
    else:
        st.info("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Log ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢")

    # --- Reset Button ---
    if st.button("üßπ ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Log ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"):
        if os.path.exists(LOG_FILE):
            try:
                os.remove(LOG_FILE)
                st.success("‚úÖ ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Log ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
                df_log = None # Update state after deletion
                st.rerun() # Rerun to reflect the change immediately
            except Exception as e:
                st.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå Log: {e}")
        else:
            st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå Log ‡πÉ‡∏´‡πâ‡∏•‡∏ö")

    st.markdown("---")

    # --- Dashboard Content (only if log exists and is not empty) ---
    if df_log is not None and not df_log.empty:
        total_cases = len(df_log)

        # --- KPI Overview ---
        st.markdown("### üí° ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå (KPI Overview)")
        col1_kpi, col2_kpi, col3_kpi = st.columns(3)

        fatal_ratio = df_log["predicted_severity"].eq("‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å").mean() * 100 if "predicted_severity" in df_log.columns else 0
        avg_age = df_log["age"].mean() if 'age' in df_log.columns and pd.api.types.is_numeric_dtype(df_log['age']) else 'N/A'
        male_ratio = df_log["sex"].eq("‡∏ä‡∏≤‡∏¢").mean() * 100 if 'sex' in df_log.columns else 'N/A' # Assuming 'sex' logs '‡∏ä‡∏≤‡∏¢'/'‡∏´‡∏ç‡∏¥‡∏á'

        col1_kpi.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏Ñ‡∏™‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", f"{total_cases:,}")
        col2_kpi.metric("‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏Ñ‡∏™‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å (Fatal)", f"{fatal_ratio:.1f}%")
        col3_kpi.metric("‡∏≠‡∏≤‡∏¢‡∏∏‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢", f"{avg_age:.1f}" if isinstance(avg_age, (int,float)) else avg_age)
        # col4_kpi.metric("‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏û‡∏®‡∏ä‡∏≤‡∏¢", f"{male_ratio:.1f}%" if isinstance(male_ratio, (int,float)) else male_ratio)


        # --- Charts ---
        st.markdown("---")
        chart_col1, chart_col2 = st.columns(2)

        # 1. Severity Distribution (Pie Chart)
        with chart_col1:
            st.markdown("##### ü©∏ ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á")
            if 'predicted_severity' in df_log.columns:
                severity_counts = df_log['predicted_severity'].value_counts()
                # Ensure correct order and colors
                severity_order = ["‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ô‡πâ‡∏≠‡∏¢", "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á", "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å"]
                severity_counts = severity_counts.reindex(severity_order, fill_value=0)
                colors_ordered = [triage_color.get(level, "#CCCCCC") for level in severity_order]

                if not severity_counts.empty and severity_counts.sum() > 0: # Check sum > 0 for pie chart
                    fig1, ax1 = plt.subplots(figsize=(4, 4))
                    # Use white text only if background colors are dark enough
                    textprops={'fontsize': 9} # Default props
                    ax1.pie(severity_counts, labels=severity_counts.index, autopct='%1.1f%%',
                            startangle=90, colors=colors_ordered,
                            textprops=textprops, wedgeprops={'edgecolor': 'white'}) # Add edge color
                    ax1.axis('equal') # Equal aspect ratio
                    # ax1.set_title("Severity Distribution", fontsize=11) # Optional title
                    st.pyplot(fig1)
                else:
                    st.caption("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á")
            else:
                st.caption("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'predicted_severity'")


        # 2. Cases over Time (Line Chart) - Requires 'timestamp'
        with chart_col2:
            st.markdown("##### üìà ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏Ñ‡∏™‡∏ï‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤")
            if 'timestamp' in df_log.columns:
                 df_log['date'] = df_log['timestamp'].dt.date
                 cases_over_time = df_log.groupby('date').size()
                 if not cases_over_time.empty:
                      st.line_chart(cases_over_time)
                 else:
                      st.caption("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Ñ‡∏™‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å")
            else:
                 st.caption("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ß‡∏•‡∏≤ (timestamp) ‡πÉ‡∏ô Log")


        # --- Risk Factor Analysis ---
        st.markdown("---")
        st.markdown("### ‚ùó ‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏™ '‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å'")

        # Define which columns represent risks in the log file
        risk_cols_in_log = [f"risk{i}" for i in range(1, 6) if f"risk{i}" in df_log.columns]
        if 'head_injury' in df_log.columns: risk_cols_in_log.append('head_injury')
        if 'is_night' in df_log.columns: risk_cols_in_log.append('is_night')
        # Add others like cannabis, amphetamine if they are logged as 0/1
        if 'cannabis' in df_log.columns: risk_cols_in_log.append('cannabis')
        if 'amphetamine' in df_log.columns: risk_cols_in_log.append('amphetamine')
        if 'drugs' in df_log.columns: risk_cols_in_log.append('drugs')


        if "predicted_severity" in df_log.columns:
            fatal_cases = df_log[df_log["predicted_severity"] == "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å"]
            if not fatal_cases.empty and risk_cols_in_log:
                # Ensure risk columns are numeric (convert bools/objects if necessary)
                for r_col in risk_cols_in_log:
                    fatal_cases[r_col] = pd.to_numeric(fatal_cases[r_col], errors='coerce').fillna(0)

                # Sum only the numeric risk columns that are truly binary (0 or 1)
                binary_risk_cols = [col for col in risk_cols_in_log if fatal_cases[col].isin([0, 1]).all()]
                if binary_risk_cols:
                    risk_counts_fatal = fatal_cases[binary_risk_cols].sum().sort_values(ascending=False)
                    # Filter out risks with zero counts
                    risk_counts_fatal = risk_counts_fatal[risk_counts_fatal > 0]

                    # Map coded risk names to readable names
                    risk_display_names = {
                        "risk1": "‡∏î‡∏∑‡πà‡∏°‡πÅ‡∏≠‡∏•‡∏Å‡∏≠‡∏Æ‡∏≠‡∏•‡πå", "risk2": "‡πÉ‡∏ä‡πâ‡∏¢‡∏≤‡πÄ‡∏™‡∏û‡∏ï‡∏¥‡∏î", "risk3": "‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡πÄ‡∏Ç‡πá‡∏°‡∏Ç‡∏±‡∏î",
                        "risk4": "‡πÑ‡∏°‡πà‡∏™‡∏ß‡∏°‡∏´‡∏°‡∏ß‡∏Å", "risk5": "‡πÉ‡∏ä‡πâ‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå",
                        "head_injury": "‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡∏®‡∏µ‡∏£‡∏©‡∏∞", "is_night": "‡πÄ‡∏Å‡∏¥‡∏î‡∏Å‡∏•‡∏≤‡∏á‡∏Ñ‡∏∑‡∏ô",
                        "cannabis": "‡∏Å‡∏±‡∏ç‡∏ä‡∏≤", "amphetamine": "‡∏¢‡∏≤‡∏ö‡πâ‡∏≤", "drugs": "‡∏¢‡∏≤‡∏≠‡∏∑‡πà‡∏ô ‡πÜ"
                    }
                    risk_counts_fatal.index = risk_counts_fatal.index.map(risk_display_names).fillna(risk_counts_fatal.index)

                    if not risk_counts_fatal.empty:
                        fig3, ax3 = plt.subplots(figsize=(7, max(3, len(risk_counts_fatal)*0.4))) # Adjust height
                        sns.barplot(x=risk_counts_fatal.values, y=risk_counts_fatal.index, ax=ax3, palette="viridis")
                        ax3.set_xlabel("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏Ñ‡∏™ '‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å' ‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ô‡∏µ‡πâ")
                        ax3.set_ylabel("‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á")
                        plt.tight_layout()
                        st.pyplot(fig3)
                    else:
                        st.caption("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏™‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å ‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏Ñ‡πà‡∏≤ 0/1")
                else:
                     st.caption("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤ 0/1 ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Log")

            else:
                st.caption("‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏Ñ‡∏™ '‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å' ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÉ‡∏ô Log")
        else:
             st.caption("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'predicted_severity' ‡πÉ‡∏ô Log")


         # --- Insights & Recommendations ---
        st.markdown("---")
        st.markdown("### üí° ‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡πÄ‡∏ä‡∏¥‡∏á‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå")
        # Example insights based on data
        insights_generated = False
        if fatal_ratio > 10: # Example threshold
             st.warning("üö® ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏Ñ‡∏™ '‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å' ‡∏Ñ‡πà‡∏≠‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡∏™‡∏π‡∏á: ‡∏Ñ‡∏ß‡∏£‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå Triage ‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏±‡∏î‡∏™‡∏£‡∏£‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏´‡πâ‡∏≠‡∏á‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°")
             insights_generated = True
        if 'risk_counts_fatal' in locals() and not risk_counts_fatal.empty:
             top_risk = risk_counts_fatal.index[0]
             st.info(f"üìå ‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏™ '‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å' ‡∏Ñ‡∏∑‡∏≠ '{top_risk}': ‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏£‡∏ì‡∏£‡∏á‡∏Ñ‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏ï‡∏£‡∏Å‡∏≤‡∏£‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ô‡∏µ‡πâ")
             insights_generated = True

        if not insights_generated:
             st.info("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Log ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥")


    else: # If df_log is None or empty or failed to load
        st.info("‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÉ‡∏ô‡πÅ‡∏ó‡πá‡∏ö 'Clinical Risk Prediction' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà")
        if log_load_error:
            st.error(f"‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Log ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {log_load_error}")


st.markdown("---")
st.markdown("Developed by AI for Road Safety | Data Source: Injury Surveillance (IS) - MOPH")
